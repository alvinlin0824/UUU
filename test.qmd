---
title: "Untitled"
format: html
execute: 
  eval: false
---

```{r}
#| message: false
# library(vroom)
library(fs)
library(tidyverse)
# library(janitor)
# library(gt)
# library(ega)
```

```{r}
file_list <- dir_ls(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\CDM_23238\005\GKS)"), recurse = T, regexp = "*devices.csv$|*readings.csv$") |> 
             path_filter(regexp = "Transfer|Transfers|Archive|Archives", invert = T, ignore.case = TRUE)
```

```{r}
devices <- path_filter(file_list, regexp = "devices.csv")
readings <- path_filter(file_list, regexp = "readings.csv")
```

```{r}
tibble(x = devices, y = readings) |> View()
```

```{r}
devices_readings <- function(devices_path, readings_path, index = NULL){
 
 if (length(devices_path) != length(readings_path)) {rlang::abort("Number of devices.csv is not equal to number of readings.csv!")}
  
 if (!is.numeric(index) && !is.null(index)) {rlang::abort("Index must be numeric!")}
  
 if(is.numeric(index)) {
    if (index > length(devices_path) || index > length(readings_path)) {rlang::abort("Index beyond the range!")}
 
    else {      
      map2(
      # Devices.csv
      devices_path[index] |> 
        set_names() |>
        map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SubjectID = "c", activationTimeUTC = "T"), show_col_types = F, col_select = c(SubjectID, ConditionID, sensorSN, activationTimeUTC)), tibble::tibble()), .progress = T) |> 
        map(\(df) df |> rename(timeUTC = activationTimeUTC)),
      # readings.csv  
      readings_path[index] |> 
          set_names() |>
          map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SubjectID = "c", timeUTC = "T", reading = "d"), show_col_types = F, col_select = c(SubjectID, ConditionID, timeUTC, reading, analyte, DataType)), tibble::tibble()), .progress = T), bind_rows) |> 
      # Fill sensor serial number 
      map(\(df) df |> fill(sensorSN), .progress = T) |> 
      list_rbind(names_to = "Path") |> 
      transmute(Path = Path,
                `Subject ID` = SubjectID,
                `Condition ID` = ConditionID,
                `Sensor Serial Number` = sensorSN,
                `Date Time` = force_tz(with_tz(timeUTC, tzone = "US/Pacific"), tzone = "UTC"),
                 Type = case_when(DataType == "raw" ~ "906",
                                  DataType == "historical" ~ "905",
                                  .default = "SENSOR_STARTED (58)"),
                 Reading = reading,
                 Analyte = analyte) |> 
      suppressWarnings()
 }
   } 
  else if (is.null(index)) {
     map2(
    # Devices.csv
    devices_path |> 
    set_names() |>
    map(\(path) vroom::vroom(path, delim = ",", show_col_types = F, col_types = c(SubjectID = "c", activationTimeUTC = "T"), col_select = c(SubjectID, ConditionID, sensorSN, activationTimeUTC)), .progress = T) |> 
    map(\(df) df |> rename(timeUTC = activationTimeUTC)),
    # readings.csv  
    readings_path |> 
      set_names() |>
      map(\(path) vroom::vroom(path, delim = ",", show_col_types = F, , col_types = c(SubjectID = "c", timeUTC = "T", reading = "d"), col_select = c(SubjectID, ConditionID, timeUTC, reading, analyte, DataType)), .progress = T), bind_rows) |> 
  # Fill sensor serial number 
  map(\(df) df |> fill(sensorSN), .progress = T) |> 
  list_rbind(names_to = "Path") |> 
  transmute(Path = Path,
            `Subject ID` = SubjectID,
            `Condition ID` = ConditionID,
            `Sensor Serial Number` = sensorSN,
            `Date Time` = force_tz(with_tz(timeUTC, tzone = "US/Pacific"), tzone = "UTC"),
             Type = case_when(DataType == "raw" ~ "906",
                              DataType == "historical" ~ "905",
                              .default = "SENSOR_STARTED (58)"),
             Reading = reading,
             Analyte = analyte) |> 
   suppressWarnings()
  }
}
```

```{r}
devices_readings(devices_path = devices, readings_path = readings) |> View()
```

```{r}
map2(
  (file_list |> 
  path_filter(regexp = "devices.csv"))[1] |> 
  set_names() |>
  map(\(path) vroom::vroom(path,show_col_types = F,col_select = c(SubjectID,ConditionID,sensorSN,activationTimeUTC)),.progress = T) |> 
  map(\(df) df |> rename(timeUTC = activationTimeUTC)),
  (file_list |> 
  path_filter(regexp = "readings.csv"))[1] |> 
  set_names() |>
         map(\(path) vroom::vroom(path,show_col_types = F,col_select = c(SubjectID,ConditionID,timeUTC,reading,analyte,DataType)),.progress = T),
  bind_rows) |> 
  map(\(df) df |> fill(sensorSN)) |> 
  list_rbind(names_to = "Path") |> 
  transmute(Path = Path,
            `Subject ID` = SubjectID,
            `Condition ID` = ConditionID,
            `Sensor Serial Number` = sensorSN,
            `Date Time` = force_tz(with_tz(timeUTC, tzone = "US/Pacific"), tzone = "UTC"),
             Type = case_when(DataType == "raw" ~ "906",
                              DataType == "historical" ~ "905",
                              .default = "SENSOR_STARTED (58)"),
             Reading = reading,
             Analyte = analyte)
   # pull(`Date Time`)
```


<!-- Atna -->

<!-- 193, 210 and 215 -->

```{r}
#| label: Find all events gluc and freestyle files csv
file_list <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-21210\UploadData\AUU\AUU_DataFiles)"),recurse = T,glob = "*events.csv|*gluc.csv|*freestyle.csv")
```

```{r}
events_path <- file_list[str_detect(file_list,"events") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
gluc_path <- file_list[str_detect(file_list,"gluc") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
#| warning: false
atna1(events = events_path,gluc = gluc_path,index = 1) |> View()
```

```{r}
atna1 <- function(events, gluc, index = NULL) {

  # Individual File
  if (is.numeric(index)) {
    purrr::map2(
      # First List
      # Import Events
      events[index] |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      purrr::map2(
        # Second List
        # Import gluc.csv
        gluc[index] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        gluc[index] |>
          purrr::map(possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                  dplyr::case_when(
                                      # Site ID == ADC
                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T)),
                                      # Site ID == 009
                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081
                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = stringr::str_extract(df[2,1],stringr::regex("(?<=Reader_S_N ).{13}",ignore_case = T)),
                                  `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n()),.progress = TRUE),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path")

  } else {

    # All Upload Data
    purrr::map2(
      # First List
      # Import Events
      events |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      purrr::map2(
        # Second List
        # Import gluc.csv
        gluc |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        gluc |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                    dplyr::case_when(
                                      # Site ID == ADC
                                      stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T)),
                                      # Site ID == 009
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = stringr::str_extract(df[2,1],stringr::regex("(?<=Reader_S_N ).{13}",ignore_case = T)),
                                  `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n()),.progress = TRUE),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      dplyr::distinct() |>
      dplyr::arrange(Path,`Subject ID`,`Condition ID`,`Sensor Serial Number`)
  }
}
```

```{r}
library(UUU)
```

```{r}
#| warning: false
atna(events = events_path,gluc = gluc_path) |> View()
```

<!-- Apol -->

```{r}
#| label: Find all events gluc and freestyle files csv
file_list <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-VAL-21206\UploadData\AUU\AUU_DataFiles)"),recurse = T,glob = "*events.csv|*gluc.csv|*freestyle.csv")
```

```{r}
events_path <- file_list[str_detect(file_list,"events") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
#| warning: false
events(events_path = events_path)
```

```{r}
gluc_path <- file_list[str_detect(file_list,"gluc") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
free_path <- file_list[str_detect(file_list,"freestyle") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
#| warning: false
freestyle(freestyle_path = free_path)
```

```{r}
#| warning: false
apol(events = events_path,gluc = gluc_path)
```

<!-- Apol 22222 -->

```{r}
file_list <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-PMS-22222\UploadData)"),recurse = T,glob = "*events.csv|*freestyle.csv|*gluc.csv")
```

```{r}
events_path <- file_list[str_detect(file_list,"events")  & !str_detect(file_list,regex("Transfers",ignore_case = T))]
gluc_path <- file_list[str_detect(file_list,"gluc") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
free_path <- file_list[str_detect(file_list,"freestyle") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
apol <- function(events, gluc, index = NULL) {

  # Individual File
  if (is.numeric(index)) {
    map2(
      # First List
      # Import Events
      events[index] |>
        set_names() |>
        # Consider empty events.csv
        map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble()),.progress = TRUE) |>
        map(\(df) df |> filter(Type == "SENSOR_STARTED (58)")) |>
        map(\(df) df |> transmute(
          `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`)),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      map2(
        # Second List
        # Import gluc.csv
        gluc[index] |>
          map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble())),
        gluc[index] |>
          map(possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character")),tibble())),
        bind_rows,.progress = TRUE) |>
        map(\(df) df |> transmute(`Subject ID` =
                                    case_when(
                                      # Site ID == ADC
                                      str_to_upper(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = 00).{1}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081 or 057
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ str_c(str_extract(df[1,1],regex("(?<=Site ID = 0).{2}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = str_c(str_extract(df[1,1],regex("(?<=Site ID = )[:alpha:]+",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = str_extract(df[1,1],regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = str_extract(df[2,1],regex("(?<=\\s).{13}",ignore_case = T)),
                                  `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr)) |>
        map(\(df) df |> slice(3:n())),bind_rows) |>
      map(\(df) df |>  arrange(`Date Time`)) |>
      map(\(df) df |> fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up")) |>
      map(\(df) df |> fill(`Sensor Serial Number`,.direction = "down")) |>
      map(\(df) df |> relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr)) |>
      list_rbind(names_to = "Path")

  } else {

    # All Upload Data
    map2(
      # First List
      # Import Events
      events |>
        set_names() |>
        # Consider empty events.csv
        map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble()),.progress = TRUE) |>
        map(\(df) df |> filter(Type == "SENSOR_STARTED (58)")) |>
        map(\(df) df |> transmute(
          `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`)),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      map2(
        # Second List
        # Import gluc.csv
        gluc |>
          map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble())),
        gluc |>
          map(possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character")),tibble())),
        bind_rows,.progress = TRUE) |>
        map(\(df) df |> transmute(`Subject ID` =
                                    case_when(
                                      # Site ID == ADC
                                      str_to_upper(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = 00).{1}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081 or 057
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ str_c(str_extract(df[1,1],regex("(?<=Site ID = 0).{2}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = str_c(str_extract(df[1,1],regex("(?<=Site ID = )[:alpha:]+",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = str_extract(df[1,1],regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = str_extract(df[2,1],regex("(?<=\\s).{13}",ignore_case = T)),
                                  `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr)) |>
        map(\(df) df |> slice(3:n())),bind_rows) |>
      map(\(df) df |> arrange(`Date Time`)) |>
      map(\(df) df |> fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up")) |>
      map(\(df) df |> fill(`Sensor Serial Number`,.direction = "down")) |>
      map(\(df) df |> relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr)) |>
      list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      distinct() |>
      arrange(Path,`Subject ID`,`Condition ID`,`Sensor Serial Number`)
  }
}
```

```{r}
apol(events = events_path[1:5],gluc = gluc_path[1:5]) |> View()
```

```{r}
   map2(
      # First List
      # Import Events
     events_path[1] |>
        set_names() |>
        # Consider empty events.csv
        map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble()),.progress = TRUE) |>
        map(\(df) df |> filter(Type == "SENSOR_STARTED (58)")) |>
        map(\(df) df |> transmute(
          `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`)),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      map2(
        # Second List
        # Import gluc.csv
        gluc_path[1] |>
          map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble())),
        gluc_path[1] |>
          map(possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character")),tibble())),
        bind_rows,.progress = TRUE) |>
        map(\(df) df |> transmute(`Subject ID` =
                                    case_when(
                                      # Site ID == ADC
                                      str_to_upper(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = 00).{1}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081 or 057
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ str_c(str_extract(df[1,1],regex("(?<=Site ID = 0).{2}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = str_c(str_extract(df[1,1],regex("(?<=Site ID = )[:alpha:]+",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = str_extract(df[1,1],regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = str_extract(df[2,1],regex("(?<=\\s).{13}",ignore_case = T)),
                                  `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr)) |>
        map(\(df) df |> slice(3:n())),bind_rows) |>
      map(\(df) df |>  arrange(`Date Time`)) |>
      map(\(df) df |> fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up")) |>
      map(\(df) df |> fill(`Sensor Serial Number`,.direction = "down")) |>
      map(\(df) df |> relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr)) |>
      list_rbind(names_to = "Path") |> View()
```

```{r}
UUU::apol(events = events_path,gluc = gluc_path)
```

```{r}
UUU::freestyle(freestyle_path = free_path,index = 1)
```

```{r}
#| warning: false
apol(events = events_path,gluc = gluc_path,index = 4)
```

```{r}
#| warning: false
saveRDS(UUU::apol(events = events_path,gluc = gluc_path),gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-PMS-22222_SiBionics\Statistics\Programs\Datasets\AL\UUU.rds)"))
```

```{r}
#| warning: false
saveRDS(UUU::freestyle(freestyle_path = free_path,index = 1),gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-PMS-22222_SiBionics\Statistics\Programs\Datasets\AL\BG.rds)"))
```

<!-- Mobi IH102 -->

```{r}
#| label: Find all events gluc and freestyle files csv
file_list <- dir_ls(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\CDM_16157\102\UUU\102UUUFIN_G1L1_3\29SEP2022_G1L3)"),recurse = T,glob = "*events.csv|*gluc.csv|*freestyle.csv")
```

```{r}
events_path <- file_list[str_detect(file_list,"events") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
gluc_path <- file_list[str_detect(file_list,"gluc") & !str_detect(file_list,regex("Transfers",ignore_case = T))]
```

```{r}
#| warning: false
mobi(events = events_path,gluc = gluc_path) |> View()
```

<!-- events -->

<!-- IH115 -->

```{r}
#| label: Find all events gluc and freestyle files csv
file_list1 <- dir_ls(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\CDM_16157\115\UUU)"),recurse = T,glob = "*events.csv")
```

```{r}
#| label: Filter events index 300
events_path <- file_list1[str_detect(file_list1,"events") & !str_detect(file_list1,"Archive")]
```

<!-- IH115 -->

<!-- 206 -->

```{r}
#| label: OUS Import all events, gluc and glucPlus files csv
file_list <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-VAL-21206\Processing\R-FSL2-LVC-G3-OUS\glucplusOutput)"),recurse = T,glob = "*events.csv|*glucPlus.csv|*gluc.csv")
```

<!-- 584 files -->

```{r}
#| label: Filter events index 237
events_path <- file_list[str_detect(file_list,"events")]
```

<!-- 206 -->

```{r}
#| warning: false
  events_path[314:316] |>
      map(possibly(\(path) vroom(path,delim = ",",
                                 col_names = T,
                                 show_col_types = F,
                                 col_types = c(`Col 5` = "c",`Col 9` = "c"),
                                 col_select = 
                                   c(`Unique Record ID`,Date,Time,Type,`Col 5`,`Col 9`)),
          tibble()),.progress = TRUE) |>
      map(\(df) df |>
            transmute(`Subject ID` =
                        case_when(
                          # Site ID == ADC
                          str_to_upper(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T)),
                          # Site ID == 009
                          str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                            str_c(str_extract(df[1,1],regex("(?<=Site ID = 00).{1}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                          # Site ID starts with 1
                          str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                            str_c(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                          # Site ID == 081
                          .default = str_c(str_extract(df[1,1],regex("(?<=Site ID = 0).{2}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T)))
                        ),
                      `Condition ID` = str_extract(df[1,1],regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                      `Reader ID` = str_extract(df[2,1],regex("(?<=\\s).{13}",ignore_case = T)),
                      `Sensor Serial Number` = `Col 5`,
                      `Col 9` = `Col 9`,
                      `Event Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
                       Type = Type)) |>
        map(\(df) df |> filter(!is.na(Type))) |> 
        map(\(df) df |> mutate(`Col 9` = case_when(str_detect(`Col 9`,"[:alpha:]") ~ `Col 9`,
                                   .default = NA_character_),
                               `Sensor Serial Number` = case_when(
                                str_detect(`Sensor Serial Number`,"[:alpha:]") 
                                 ~ `Sensor Serial Number`,
                                 .default = `Col 9`))) |> 
        map(\(df) df |> fill(`Sensor Serial Number`,.direction = "updown")) |> 
        list_rbind() |> 
        select(!`Col 9`) |> 
        distinct() |> 
        arrange(`Subject ID`,`Condition ID`)
      #   list_rbind() |>
      # # Remove Duplicated
      #   distinct() |>
      # Remove Type is NA
        # filter(!is.na(Type)) |> 
        # mutate(`Col 9` = case_when(str_detect(`Col 9`,"[:alpha:]") ~ `Col 9`,
        #                            .default = NA_character_),
        #        `Sensor Serial Number` = case_when(
        #          str_detect(`Sensor Serial Number`,"[:alpha:]") ~ `Sensor Serial Number`,
        #            .default = `Col 9`)) |> 
        # fill(`Sensor Serial Number`,.direction = "up") |> 
        # select(!`Col 9`) |> View()
        # arrange(`Subject ID`,`Condition ID`) |> 
```

<!-- 225 SE14 Site ID = CIG -->

```{r}
#| label: Find all events and gluc files csv
file_list <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-22225\SE14_Glu\UploadData\UUU\UUU_DataFiles\TDE-082)"),recurse = T,glob = "*events.csv|*gluc.csv|*freestyle.csv")
```

```{r}
#| label: Filter all and find events 
events_path <- file_list[!str_detect(file_list,"Transfers|FV_Do Not Use") & str_detect(file_list,"events")]
```

```{r}
#| label: Filter all and find gluc
gluc_path <- file_list[!str_detect(file_list,"Transfers|FV_Do Not Use") & str_detect(file_list,"gluc")]
```

```{r}
#| warning: false
UUU::apol(events = events_path,gluc = gluc_path,index = 20) |> View()
```

```{r}
#| warning: false
    map2(
      # First List
      # Import Events
      events_path[92:94] |>
        # Consider empty events.csv
        map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble()),.progress = TRUE) |>
        map(\(df) df |> filter(Type == "SENSOR_STARTED (58)")) |>
        map(\(df) df |> transmute(
          `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`)),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      map2(
        # Second List
        # Import gluc.csv
        gluc_path[92:94] |>
          set_names() |> 
          map(possibly(\(path) vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble())),
        gluc_path[92:94] |>
          set_names() |> 
          map(possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character")),tibble())),
        bind_rows,.progress = TRUE) |>
        map(\(df) df |> transmute(`Subject ID` =
                                    case_when(
                                      # Site ID == ADC
                                      str_to_upper(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = 00).{1}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081
                                     str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "08" ~ str_c(str_extract(df[1,1],regex("(?<=Site ID = 0).{2}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                     # Site ID mislabeled  
                                     .default = str_c(str_extract(df[1,1],regex("(?<=Site ID = )[:alpha:]+",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = str_extract(df[1,1],regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = str_extract(df[2,1],regex("(?<=\\s).{13}",ignore_case = T)),
                                  `Date Time` = ymd_hms(str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr)) |>
        map(\(df) df |> slice(3:n())),bind_rows) |>
      map(\(df) df |>  arrange(`Date Time`)) |>
      map(\(df) df |> fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up")) |>
      map(\(df) df |> fill(`Sensor Serial Number`,.direction = "down")) |>
      map(\(df) df |> relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr)) |>
      list_rbind(names_to = "Path") |> 
      arrange(Path,`Subject ID`,`Condition ID`,`Sensor Serial Number`) |> 
      View()
```

<!-- Mobi IH116 -->

```{r}
#| label: Find all events gluc and freestyle files csv
file_list <- dir_ls(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\CDM_16157\116)"),recurse = T,glob = "*events.csv|*glucPlus.csv|*freestyle.csv")
```

```{r eval = params$interim}
#| label: Interim Filter events, glucplus and freestyle
events_path <- UUU::filter_path(file_path = file_list,filter_text = "UUUFIN|BGM")[[1]] 
glucplus_path <- UUU::filter_path(file_path = file_list,filter_text = "UUUFIN|BGM")[[3]]
free_path <- UUU::filter_path(file_path = file_list,filter_text = "UUUFIN|AUUFIN")[[4]]
```

```{r}
mobi1 <- function(events, gluc, index = NULL) {

  # Individual File
  if (is.numeric(index)) {
    map2(
      # First List
      # Import Events
      events[index] |>
        set_names() |>
        # Consider empty events.csv
        map(possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble()),.progress = TRUE) |>
        map(\(df) df |> filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        map(\(df) df |> transmute(
          `Date Time` = case_when(str_starts(Date,"[:digit:]{4}") ~
                                    ymd_hms(format(as.POSIXct(str_c(Date,Time,sep = " "),tz = "UTC"),tz="US/Pacific",format = "%Y-%m-%d:%H:%M:%S"),tz = "US/Pacific"),
                                  .default = ymd_hms(format(as.POSIXct(str_c(mdy(Date),Time,sep = " "),tz = "UTC"),tz="US/Pacific",format = "%Y-%m-%d:%H:%M:%S"),tz = "US/Pacific")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),
      # Replaced Sensors Only
      # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      map2(
        # Second List
        # Import gluc.csv
        gluc[index] |>
          map(possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Date = "c", Time = "c", Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl),n_max = 2),tibble()),.progress = TRUE),
        gluc[index] |>
          map(possibly(\(path) data.table::fread(path,select = c(1:5),skip = 2,col.names = c("Unique Record ID","Date","Time","Type","Gl"),colClasses = c("V2" = "character","V3" = "character","V4" = "character")),tibble()),.progress = TRUE),
        bind_rows,.progress = TRUE) |>
        map(\(df) df |> transmute(`Subject ID` =
                                    case_when(
                                      # Site ID == ADC
                                      str_to_upper(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T)),
                                      # Site ID == 009
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = 00).{1}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ str_c(str_extract(df[1,1],regex("(?<=Site ID = 0).{2}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = str_c(str_extract(df[1,1],regex("(?<=Site ID = )[:alpha:]+",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = str_extract(df[1,1],regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Date Time` = case_when(str_starts(Date,"[:digit:]{4}") ~
                                                            ymd_hms(str_c(ymd(Date),hms::as_hms(Time),sep = " "),tz = "US/Pacific"),.default = ymd_hms(str_c(mdy(Date),hms::as_hms(Time),sep = " "),tz = "US/Pacific")),
                                  Type = Type,
                                  Gl = Gl),.progress = TRUE) |>
        map(\(df) df |> slice(2:n())),bind_rows,.progress = TRUE) |>
      map(\(df) df |> arrange(`Date Time`),.progress = TRUE) |>
      map(\(df) df |> fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      map(\(df) df |> fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      # map(\(df) df |> filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      map(\(df) df |> relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Date Time`,Type,Gl),.progress = TRUE) |>
      list_rbind(names_to = "Path")

  } else {

    # All Upload Data
    map2(
      # First List
      # Import Events
      events |>
        set_names() |>
        # Consider empty events.csv
        map(possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble()),.progress = TRUE) |>
        map(\(df) df |> filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        map(\(df) df |> transmute(
          `Date Time` = case_when(str_starts(Date,"[:digit:]{4}") ~
                                    ymd_hms(format(as.POSIXct(str_c(Date,Time,sep = " "),tz = "UTC"),tz="US/Pacific",format = "%Y-%m-%d:%H:%M:%S"),tz = "US/Pacific"),
                                  .default = ymd_hms(format(as.POSIXct(str_c(mdy(Date),Time,sep = " "),tz = "UTC"),tz="US/Pacific",format = "%Y-%m-%d:%H:%M:%S"),tz = "US/Pacific")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),

      map2(
        # Second List
        # Import gluc.csv
        gluc |>
          map(possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Date = "c", Time = "c", Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl),n_max = 2),tibble()),.progress = TRUE),
        gluc |>
          map(possibly(\(path) data.table::fread(path,select = c(1:5),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl"),colClasses = c("V2" = "character","V3" = "character","V4" = "character")),tibble()),.progress = TRUE),
        bind_rows,.progress = TRUE) |>
        map(\(df) df |> transmute(`Subject ID` =
                                    case_when(
                                      # Site ID == ADC
                                      str_to_upper(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T)),
                                      # Site ID == 009
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = 00).{1}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        str_c(str_extract(df[1,1],regex("(?<=Site ID = ).{3}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081
                                      str_extract(df[1,1],regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ str_c(str_extract(df[1,1],regex("(?<=Site ID = 0).{2}",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = str_c(str_extract(df[1,1],regex("(?<=Site ID = )[:alpha:]+",ignore_case = T)),str_extract(df[1,1],regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = str_extract(df[1,1],regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Date Time` = case_when(str_starts(Date,"[:digit:]{4}") ~
                                                            ymd_hms(str_c(ymd(Date),hms::as_hms(Time),sep = " "),tz = "US/Pacific"),.default = ymd_hms(str_c(mdy(Date),hms::as_hms(Time),sep = " "),tz = "US/Pacific")),
                                  Type = Type,
                                  Gl = Gl),.progress = TRUE) |>
      map(\(df) df |> slice(2:n())),bind_rows,.progress = TRUE) |>
      map(\(df) df |> arrange(`Date Time`),.progress = TRUE) |>
      map(\(df) df |> fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      map(\(df) df |> fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      map(\(df) df |> filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      map(\(df) df |> relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Date Time`,Type,Gl),.progress = TRUE) |>
      list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      distinct() |>
      arrange(Path,`Subject ID`,`Condition ID`,`Sensor Serial Number`)
  }
}
```

<!-- 34,76 empty -->

```{r}
#| warning: false
mobi1(events = events_path,gluc = glucplus_path,index = 76) |> View()
```

<!-- Mobi ANA -->

```{r}
#| label: Import ketone events, anaplus files csv
#| eval: false
file_list_ketone <- dir_ls(gsub("\\\\", "/", r"(C:\UDP\OutputFiles\Output_2023-11-02-13-54\outputs)"),recurse = T,glob = "*events.csv|*anaPlus.csv")
```

```{r}
#| label: Ketone Filter events, anaPlus
#| eval: false
events_path_ketone <- UUU::filter_path(file_path = file_list_ketone)[[1]]
anaplus_path_ketone <- file_list_ketone[str_detect(file_list_ketone,"anaPlus.csv")]
```

```{r}
#| warning: false
#| eval: false
mobi_ana <- function(events, ana, index = NULL) {

  # Individual File
  if (is.numeric(index)) {
    purrr::map2(
      # First List
      # Import Events
      events[index] |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),

      purrr::map2(
        # Second List
        # Import anaPlus.csv or ana.csv
        ana[index] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Date = "c", Time = "c", Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,ANA,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        ana[index] |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:5,7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","ANA","Tr"),colClasses = c("V2" = "character","V3" = "character","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |> 
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                    dplyr::case_when(
                                      # Site ID == ADC
                                      stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081 or 057
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                  Type = Type,
                                  ANA = ANA,
                                  Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(2:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Date Time`,Type,ANA,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path")

  } else {

    # All Upload Data
    purrr::map2(
      # First List
      # Import Events
      events |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),

      purrr::map2(
        # Second List
        # Import anaPlus.csv or ana.csv
        ana |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Date = "c", Time = "c", Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,ANA,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        ana |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:5,7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","ANA","Tr"),colClasses = c("V2" = "character","V3" = "character","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |> 
        purrr::map(\(df) df |> dplyr::transmute(
                                   `Subject ID` =
                                    dplyr::case_when(
                                      # Site ID == ADC
                                      stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081 or 057
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                  Type = Type,
                                  ANA = ANA,
                                  Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(2:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Date Time`,Type,ANA,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      dplyr::distinct() |>
      dplyr::arrange(Path,`Subject ID`,`Condition ID`,`Sensor Serial Number`)
  }
}
```

```{r}
#| warning: false
a <- mobi_ana(events = events_path_ketone[2],ana = anaplus_path_ketone[2])
b <- mobi_ana(events = events_path_ketone,ana = anaplus_path_ketone,index = 2)
```

```{r}
b[duplicated(b),] |> View()
```

```{r}
a |> dplyr::intersect(b |> distinct())
b |> dplyr::setdiff(a)
```

<!-- Oneminutes -->

```{r}
file_list <- dir_ls(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\CDM_23238\004\UUU)"),recurse = T,glob = "*events.csv|*glucPlus.csv|*oneMinutes.csv")
```

```{r}
events_path <- file_list[str_detect(file_list,"events.csv") & !str_detect(file_list,"Archive")]
glucplus_path <- file_list[str_detect(file_list,"glucPlus.csv") & !str_detect(file_list,"Archive")]
```

```{r}
      purrr::map2(
        # Second List
        # Import gluc.csv
        glucplus_path[1] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        glucplus_path[1] |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character"),fill = T),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |> 
           list_rbind() |>  
           View()
```

```{r}
apol <- function(events, gluc, index = NULL) {

  # Individual File
  if (is.numeric(index)) {
    purrr::map2(
      # First List
      # Import Events
      events[index] |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      purrr::map2(
        # Second List
        # Import gluc.csv
        gluc[index] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        gluc[index] |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character"),fill = T),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                    dplyr::case_when(
                                      # Site ID == ADC
                                      stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081 or 057
                                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = stringr::str_extract(df[2,1],stringr::regex("(?<=\\s).{13}",ignore_case = T)),
                                  `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n()),.progress = TRUE),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path")

  } else {

    # All Upload Data
    purrr::map2(
      # First List
      # Import Events
      events |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),
        # Replaced Sensors Only
        # map(\(df) df |> slice_max(`Date Time`,n = 1)),

      purrr::map2(
        # Second List
        # Import gluc.csv
        gluc |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,Gl,St,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        gluc |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","Gl","St","Tr"),colClasses = c("V2" = "Date","V4" = "character"),fill = T),tibble::tibble()),.progress = TRUE),
        bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                  dplyr::case_when(
                                      # Site ID == ADC
                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                      # Site ID == 009
                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID starts with 1
                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                      # Site ID == 081 or 057
                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                      # Site ID mislabeled
                                      .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                    ),
                                  `Condition ID` = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
                                  `Reader ID` = stringr::str_extract(df[2,1],stringr::regex("(?<=\\s).{13}",ignore_case = T)),
                                  `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                   Type = Type,
                                   Gl = Gl,
                                   St = St,
                                   Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n()),.progress = TRUE),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`,`Reader ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                               `Reader ID`,`Date Time`,Type,Gl,St,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      dplyr::distinct() |>
      dplyr::arrange(Path,`Subject ID`,`Condition ID`,`Sensor Serial Number`)
  }
}
```

```{r}
#| warning: false
apol(events = events_path,gluc = glucplus_path) |> View()
```

<!-- Sibionics -->

\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-23241\SE01\UploadData\SiBionics \\wf00168p.oneabbott.com\data1\CDM\ADC-US-PMS-22222\UploadData\SiBionics\\083-IDR

```{r}
sib_list <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-23241\SE01\UploadData\SiBionics)"),recurse = T,glob = "*xlsx|*csv")
sib_path <- sib_list[!str_detect(sib_list,regex("Transfers",ignore_case = T))]
```

\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-23241\SE01\UploadData\SiBionics\\0830001 //wf00168p.oneabbott.com/data1/CDM/ADC-US-PMS-22222/UploadData/SiBionics/083-IDR/0830002/FV/0830002_SiSensingCGM-LT22050X74-01.11.00.00.xlsx

```{r}
sibonics1 <- function(sibonics_path, index = NULL){

if (is.numeric(index)) {
   if(str_detect(sibonics_path[index],".xlsx")){
# .xlsx
sibonics_path[index][str_detect(sibonics_path[index],".xlsx")] |>
       set_names() |>
       map(\(path) readxl::read_excel(path,col_names = T,col_types = c("guess","guess"))) |>
       list_rbind(names_to = "Path") |>
       transmute(Path = Path,
                 `Subject ID` = str_extract(Path,"(?<=0)[:digit:]{6}"),
                 `Date Time` = ymd_hm(),
                  Gl = as.numeric(na_if(,"")))
   } else {
# .csv
sibonics_path[index][str_detect(sibonics_path[index],".csv")] |> 
  set_names() |>
         map(possibly(\(path) vroom::vroom(path,delim = ",",show_col_types = F,col_select = c(ast,t,name,v,vSecond),col_types = c(ast = "d", t = "d", v = "d", vSecond = "d")),tibble::tibble()),.progress = TRUE) |>
        list_rbind(names_to = "Path") |> 
        mutate(`Subject ID` = str_extract(Path,"(?<=0)[:digit:]{6}"),
               `Date Time` = floor_date(as_datetime(t/1000,tz = "UTC"),"min"),
                Gl = v) |> 
        # One-hour Warn up
        filter(`Date Time` >= first(`Date Time`) + dminutes(59),.by = `Subject ID`) |> 
        # Valid Glucose Reading
        filter(vSecond != 0) |> 
        # Assign abnormal
        transmute(Path = Path,
                 `Subject ID` = `Subject ID`,
                 `Date Time` = `Date Time`,
                  Gl = case_when(ast == 2 ~ NA,
                                .default = Gl))
   }
} else {
    # .xlsx
sibonics_path[str_detect(sibonics_path,".xlsx")] |>
       set_names() |>
       map(\(path) readxl::read_excel(path,col_names = T,col_types = c("guess","guess"))) |>
       list_rbind(names_to = "Path") |>
       transmute(Path = Path,
                 `Subject ID` = str_extract(Path,"(?<=0)[:digit:]{6}"),
                 `Date Time` = ymd_hm(),
                  Gl = as.numeric(na_if(,""))) |> 
      bind_rows(
        # .csv
sibonics_path[str_detect(sibonics_path,".csv")] |> 
  set_names() |>
        map(possibly(\(path) vroom::vroom(path,delim = ",",show_col_types = F,col_select = c(ast,t,name,v,vSecond),col_types = c(ast = "d", t = "d", v = "d", vSecond = "d")),tibble::tibble()),.progress = TRUE) |>
        list_rbind(names_to = "Path") |> 
        mutate(`Subject ID` = str_extract(Path,"(?<=0)[:digit:]{6}"),
               `Date Time` = floor_date(as_datetime(t/1000,tz = "UTC"),"min"),
                Gl = v) |> 
        # One-hour Warn up
        filter(`Date Time` >= first(`Date Time`) + dminutes(59),.by = `Subject ID`) |> 
        # Valid Glucose Reading
        filter(vSecond != 0) |> 
        # Assign abnormal
        transmute(Path = Path,
                 `Subject ID` = `Subject ID`,
                 `Date Time` = `Date Time`,
                  Gl = case_when(ast == 2 ~ NA,
                                .default = Gl))) |> 
        arrange(`Subject ID`)
  }
}
```

```{r}
sibonics1(sibonics_path = sib_path) |> View()
```

<!-- Difference Measures -->

```{r}
#| label: Import Ap.rds
Ap <- readRDS(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-VAL-21206 iCGM Libre 2\Statistics\Programs\Canada\Datasets\Ap.rds)"))
```

```{r}
#| label: Import BG.rds
BG <- readRDS(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-PMS-22222_SiBionics\Statistics\Programs\Datasets\AL\BG.rds)"))
UUU <- readRDS(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-PMS-22222_SiBionics\Statistics\Programs\Datasets\AL\UUU.rds)"))
Sib <- readRDS(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-PMS-22222_SiBionics\Statistics\Programs\Datasets\AL\Sib.rds)"))
```

```{r}
#| label: Pair Function
PAIRBG_fun <- function(data){
  # BG Strips Data
  BG %>%
     # Remove Extreme Reference readings <20 or >500
     filter(between(Reference,20,500)) %>% 
     inner_join(
               # Sensor Data
               data %>%
                select(!Path) %>% 
                mutate(
                  `Lower Bound` = case_when(Type %in% c("904","906") ~ `Date Time` - dminutes(5),
                                            .default = `Date Time` - dminutes(8)),
                  `Upper Bound` = case_when(Type %in% c("904","906") ~ `Date Time` + dminutes(5),
                                            .default = `Date Time` + dminutes(8))
                     ),
                   by = join_by("Subject ID",between(`BG Date Time`,`Lower Bound`,`Upper Bound`)),
                   multiple = "all"
                     ) %>%
      # Select the nearest time
      group_by(`Subject ID`,`BG Date Time`) %>%
      arrange(desc(`Date Time`)) %>%
      slice_min(abs(`BG Date Time` - `Date Time`),n = 1,with_ties = F) %>%
      ungroup() %>%
      # Select the nearest time
      group_by(`Subject ID`,`Date Time`) %>%
      arrange(desc(`Date Time`)) %>%
      slice_min(abs(`BG Date Time` - `Date Time`),n = 1,with_ties = F) %>%
      ungroup() %>%
      select(!c(contains("Bound")))
}
```

```{r}
#| label: Paired Data
Ap_mmol <- UUU |> 
      select(!c(`Condition ID`:`Reader ID`,St,Tr)) |> 
      mutate(Sensor = "FreeStyle Libre 2",
             Gl_mmol = Gl/18.016,
             eTime = as.numeric(difftime(`Date Time`,first(`Date Time`),units = "days")),
             Day = floor(eTime) + 1,.by = c(`Subject ID`)) |> 
      filter(between(Gl,40,500)) |> 
      bind_rows(Sib |> 
                mutate(eTime = as.numeric(difftime(`Date Time`,first(`Date Time`),units = "days") + 1/24),
                Day = floor(eTime) + 1,
                Gl_mmol = Gl,
                Type = "904",
                Sensor = "SiBionics",.by = c(`Subject ID`)) |> 
                filter(between(Gl,2.2,25.0))) |> 
      # Real Time Glucose
      filter(Type == "904") |>
      group_split(`Subject ID`,Sensor) |>  
      # New anonymous function
      map(\(df) PAIRBG_fun(data = df),.progress = T) |>
      # formula syntax
      # map(~ PAIRBG_fun(data = .x)) %>%
      list_rbind() |> 
      # Row-wise Calculation
      mutate(Reference_mmol = Reference/18.016,
            # Reference glucose values < 100 mg/dL
            `Difference(mmol/L)` = Gl_mmol - Reference_mmol,
            `Absolute Difference(mmol/L)` = abs(`Difference(mmol/L)`),
            # Reference glucose values >= 100 mg/dL
            `Relative Difference(%)` = (`Difference(mmol/L)`/Reference_mmol)*100,
            `Absolute Relative Difference(%)` = abs(`Relative Difference(%)`),
            `Glucose Level(mg/dL) [mmol/L]` = UUU::fct_case_when(round(Reference + 0.001) < 54 ~ "<54 [3.0]",
                           between(round(Reference + 0.001),54,69) ~ "54 to 69 [3.0-3.8]",
                           between(round(Reference + 0.001),70,180) ~ "70 to 180 [3.9-10.0]",
                           between(round(Reference + 0.001),181,250) ~ "181 to 250 [10.0-13.9]",
                                      TRUE ~ ">250 [13.9]")) 
      # saveRDS("Ap_mmol.rds")
```

```{r}
round_normal <- function(x, digits){
    ifelse(x >= 0,round(x + 10^-(digits + 3),digits),round(x - 10^-(digits + 3),digits))
}
  
diff_calculation <- list(Mean = ~ mean(.x, na.rm = T),
                         SD = ~ sd(.x, na.rm = T),
                         Median = ~ median(.x, na.rm = T),
                         Min = ~ min(.x, na.rm = T),
                         Max = ~ max(.x, na.rm = T),
                         N = ~ sum(!is.na(.x),na.rm = T))
```

```{r}
df <- Ap  |> 
      filter(Day <= 15) |> 
      filter(between(Gl,40,400)) |> 
      select(!contains("Difference")) |>
      mutate(Difference = Gl - Reference,
            `Absolute Difference` = abs(Difference),
            `Relative Difference(%)` = (Difference/Reference)*100,
            `Absolute Relative Difference(%)` = abs(`Relative Difference(%)`))
```

```{r}
df1 <- df |> 
       mutate(# Reference Level
              Level = case_when(round(Reference + 0.001) < 100 ~ "<100 mg/dL[5.6 mmol/L]",
                                .default = ">=100 mg/dL[5.6 mmol/L]"))|>
              # Overall Reference Level
       bind_rows(df |>
                  mutate(Level = "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)")) |> 
       pivot_longer(Difference:`Absolute Relative Difference(%)`,names_to = "Measure") |>
       filter((Measure %in% c("Difference", "Absolute Difference") &
          Level %in% c("<100 mg/dL[5.6 mmol/L]", "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)")) |
          (Measure %in% c("Relative Difference(%)", "Absolute Relative Difference(%)") &
          Level %in% c(">=100 mg/dL[5.6 mmol/L]", "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)"))) |>
       group_by(pick(Level,Measure))
```

```{r}
# Diff
df1 |> 
    # User-Defined group variables `Type of Diabetes`
    group_by(pick(`Age Group`,`Reference Type`,`Type of Diabetes`),.add = TRUE) |>
    summarise_at(.vars = "value", diff_calculation) |> 
    ungroup() |> 
    left_join(

# CI
df1 |> 
    # User-Defined group variables `Type of Diabetes`
   group_by(pick(`Age Group`,`Reference Type`,`Type of Diabetes`),.add = TRUE) |> 
   group_by(`Subject ID`, .add = TRUE) |> 
   summarise(bias_mean_subj = mean(value, na.rm = T),.groups = "drop_last") |> 
   summarise(bias_mean = mean(bias_mean_subj, na.rm = T),
             bias_sd = sd(bias_mean_subj, na.rm = T)/n()**0.5,
             N = n(),.groups = "drop") |> 
   mutate(`Grand Mean (95% CI)` = str_c(round_normal(bias_mean,1), " (",
                    round_normal(bias_mean - qt(p = 0.025, df = N - 1, lower.tail = F) * bias_sd, digits = 1),
                    ",",
                    round_normal(bias_mean + qt(p = 0.025, df = N - 1, lower.tail = F) * bias_sd, digits = 1),
                    ")"),.keep = "unused"), by = join_by(Level, Measure, `Age Group`,`Reference Type`,`Type of Diabetes`)) |> 
  relocate(`Grand Mean (95% CI)`,.before = N) |> 
  
  # Round Number
   mutate(across(c(Mean:Max), ~ round_normal(.x,1))) |> 
   # Unit
   mutate(
          Level = factor(Level, levels = c("<100 mg/dL[5.6 mmol/L]",">=100 mg/dL[5.6 mmol/L]", "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)")),
          Measure = factor(Measure, levels = c("Difference","Absolute Difference","Relative Difference(%)","Absolute Relative Difference(%)"))) |> 
   arrange(pick(Level,Measure)) |> 
   arrange(pick(`Age Group`,`Reference Type`,`Type of Diabetes`)) |> 
   gt(groupname_col = c("Age Group","Reference Type","Type of Diabetes","Level")) |>
   cols_align(align = "center") |>
   fmt_number(columns = Mean:Max,decimals = 1) |>
   sub_missing(columns = everything(),missing_text = "") |>
   opt_stylize(style = 6, color = "blue")

```

```{r}
df |> 
   mutate(# Reference Level
          Level = case_when(round(Reference + 0.001) < 100 ~ "<100 mg/dL[5.6 mmol/L]",
                            .default = ">=100 mg/dL[5.6 mmol/L]"))|>
   # Overall Reference Level
   bind_rows(df |>
             mutate(Level = "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)")) |> 
   pivot_longer(Difference:`Absolute Relative Difference(%)`,names_to = "Measure") |>
   filter((Measure %in% c("Difference", "Absolute Difference") &
          Level %in% c("<100 mg/dL[5.6 mmol/L]", "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)")) |
          (Measure %in% c("Relative Difference(%)", "Absolute Relative Difference(%)") &
          Level %in% c(">=100 mg/dL[5.6 mmol/L]", "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)"))) |>
   group_by(pick(Level,Measure)) |>
   # User-Defined group variables `Type of Diabetes`
   group_by(pick(`Age Group`,`Reference Type`),.add = TRUE) |> 
   group_by(`Subject ID`, .add = TRUE) |> 
   summarise(bias_mean_subj = mean(value, na.rm = T),.groups = "drop_last") |> 
   summarise(bias_mean = mean(bias_mean_subj, na.rm = T),
             bias_sd = sd(bias_mean_subj, na.rm = T)/n()**0.5,
             N = n(),.groups = "drop") |> 
   mutate(`Grand Mean (95% CI)` = str_c(round_normal(bias_mean,1), " (",
                    round_normal(bias_mean - qt(p = 0.025, df = N - 1, lower.tail = F) * bias_sd, digits = 1),
                    ",",
                    round_normal(bias_mean + qt(p = 0.025, df = N - 1, lower.tail = F) * bias_sd, digits = 1),
                    ")"

                    ),.keep = "unused"


          ) |> View()
```

```{r}
df |>
   mutate(# Reference Level
          Level = case_when(round(Reference + 0.001) < 100 ~ "<100 mg/dL[5.6 mmol/L]",
                            .default = ">=100 mg/dL[5.6 mmol/L]")) |>
   # Overall Reference Level
   bind_rows(df |>
             mutate(Level = "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)")) |>
   pivot_longer(Difference:`Absolute Relative Difference(%)`,names_to = "Measure") |>
   filter((Measure %in% c("Difference", "Absolute Difference") &
          Level %in% c("<100 mg/dL[5.6 mmol/L]", "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)")) |
          (Measure %in% c("Relative Difference(%)", "Absolute Relative Difference(%)") &
          Level %in% c(">=100 mg/dL[5.6 mmol/L]", "Overall Levels (100 mg/dL[5.6 mmol/L] breakpoint)"))) |>
   group_by(pick(Level,Measure)) |>
   # User-Defined group variables
   group_by(pick(`Age Group`,`Reference Type`),.add = TRUE) |>
   summarise_at(.vars = "value", diff_calculation) |> 
   ungroup() |> View()
```

<!-- 7.5841449821 - qt(p = 0.975,df = 140,lower.tail = T) * 0.298975112 -->

```{r}
#| label: difference measure function
diff_measure_fun <- function(data, type = "Glucose" ,ref, cgm, breakpoint = 100, col_subject, group_var, unit = "mg/dL", reference_breakpoint = TRUE) {
  
  round_normal <- function(x, digits){
    ifelse(x >= 0,round(x + 10^-(digits + 3),digits),round(x - 10^-(digits + 3),digits))
}
  
diff_calculation <- list(Mean = ~ mean(.x, na.rm = T),
                         SD = ~ sd(.x, na.rm = T),
                         Median = ~ median(.x, na.rm = T),
                         Min = ~ min(.x, na.rm = T),
                         Max = ~ max(.x, na.rm = T),
                         N = ~ sum(!is.na(.x),na.rm = T))
df <- data |> 
      select(!contains("Difference")) |>
      mutate(Subject = as.character({{col_subject}}),
             Difference = {{cgm}} - {{ref}},
            `Absolute Difference` = abs(Difference),
            `Relative Difference(%)` = (Difference/{{ref}})*100,
            `Absolute Relative Difference(%)` = abs(`Relative Difference(%)`))



if (reference_breakpoint == TRUE) {
# Glucose
  if (str_detect(type,regex("Glucose",ignore_case = T))) {
lower_label <- if_else(unit == "mg/dL",
                       str_c("<",breakpoint," mg/dL[",round_normal(breakpoint/18.016,1)," mmol/L]"),
                       str_c("<",floor(breakpoint*18.016)," mg/dL[",breakpoint," mmol/L]")
                       ) 
upper_label <- if_else(unit == "mg/dL",
                       str_c(">=",breakpoint," mg/dL[",round_normal(breakpoint/18.016,1)," mmol/L]"),
                       str_c(">=",floor(breakpoint*18.016)," mg/dL[",breakpoint," mmol/L]")
                       ) 
overall_label <- if_else(unit == "mg/dL",
                         str_c("Overall Levels (",breakpoint," mg/dL[",round_normal(breakpoint/18.016,1)," mmol/L] breakpoint)"),
                         str_c("Overall Levels (",floor(breakpoint*18.016)," mg/dL[",breakpoint," mmol/L] breakpoint)")
                         )
}
# Ketone  
  else if (str_detect(type,regex("Ketone",ignore_case = T))) {
lower_label <- str_c("<",breakpoint," mmol/L") 
upper_label <- str_c(">=",breakpoint," mmol/L") 
overall_label <- str_c("Overall Levels (",breakpoint," mmol/L breakpoint)")
}

df1 <- df |>
       # Reference Level
       mutate(Level = if (str_detect(type,regex("Glucose",ignore_case = T))){
                        if (unit == "mg/dL") {
                        case_when(round({{ref}} + 0.001) < breakpoint ~ lower_label,
                                .default = upper_label)}
                        else if (unit == "mmol/L"){
                        case_when(round({{ref}} + 0.001,1) < breakpoint ~ lower_label,
                                .default = upper_label)}}
                      else if (str_detect(type,regex("Ketone",ignore_case = T))){
                        case_when({{ref}} < breakpoint ~ lower_label,
                                 .default = upper_label)
                      }
              ) |>
        # Overall Reference Level
        bind_rows(df |>
                   mutate(Level = overall_label)) |>
        pivot_longer(Difference:`Absolute Relative Difference(%)`,names_to = "Measure") |>
        filter((Measure %in% c("Difference", "Absolute Difference") &
                Level %in% c(lower_label, overall_label)) |
                (Measure %in% c("Relative Difference(%)", "Absolute Relative Difference(%)") &
                Level %in% c(upper_label, overall_label))) |>
        group_by(pick(Level,Measure))

# Diff Measure
df1 |> 
   # User-Defined group variables
   group_by(pick({{group_var}}),.add = TRUE) |>
   summarise_at(.vars = "value", diff_calculation) |> 
   ungroup() |> 
   left_join(
   # Confidence Interval
    df1 |> 
    # User-Defined group variables `Type of Diabetes`
    group_by(pick({{group_var}}),.add = TRUE) |> 
    # Need to think second
    group_by(Subject, .add = TRUE) |> 
    summarise(bias_mean_subj = mean(value, na.rm = T),.groups = "drop_last") |> 
    summarise(bias_mean = mean(bias_mean_subj, na.rm = T),
              bias_sd = sd(bias_mean_subj, na.rm = T)/n()**0.5,
              N = n(),.groups = "drop") |> 
    mutate(`Grand Mean (95% CI)` = str_c(round_normal(bias_mean,1), " (",
                    round_normal(bias_mean - qt(p = 0.025, df = N - 1, lower.tail = F) * bias_sd, digits = 1),
                    ",",
                    round_normal(bias_mean + qt(p = 0.025, df = N - 1, lower.tail = F) * bias_sd, digits = 1),
                    ")"),.keep = "unused")) |> 
    relocate(`Grand Mean (95% CI)`,.before = N) |>
    # Round Number
    mutate(across(c(Mean:Max), ~ round_normal(.x,1))) |>  
    # Unit
    mutate(Measure = case_when(
                  unit == "mg/dL" & Measure %in% c("Difference","Absolute Difference")
                        ~ str_c(Measure," (",unit,")"),
                  unit == "mmol/L" & Measure %in% c("Difference","Absolute Difference")
                        ~ str_c(Measure," (",unit,")"),
                  .default = Measure
                        ),
           Level = factor(Level, levels = c(lower_label,upper_label, overall_label)),
          Measure = factor(Measure, levels = c("Difference (mg/dL)","Absolute Difference (mg/dL)","Difference (mmol/L)","Absolute Difference (mmol/L)","Relative Difference(%)","Absolute Relative Difference(%)"))) |> 
    arrange(pick(Level,Measure)) |>
    arrange(pick({{group_var}})) |>
    gt(groupname_col = c(group_var,"Level")) |>
    cols_align(align = "center") |>
    fmt_number(columns = Mean:Max,decimals = 1) |>
    sub_missing(columns = everything(),missing_text = "") |>
    opt_stylize(style = 6, color = "blue") |> 
    suppressMessages()
  } else {
    gt_group_var <- group_var[1:length(group_var) - 1]
     df |>
     group_by(pick({{group_var}})) |>
     summarise(
      across(c(Difference:`Absolute Relative Difference(%)`),
              diff_calculation[1:3],.names = "{.col} {.fn}"), N = n(),.groups = "drop") |>
     relocate(N,.after = last_col()) |>   
     # Round Number
     mutate(across(contains(c("Mean","Median")), ~ round_normal(.x,1)),
            across(contains(c("SD")), ~ round_normal(.x,2))) |> 
     gt(groupname_col = c(gt_group_var))  |>
     cols_align(align = "center") |>
     tab_spanner(label = str_c("Difference"," (",unit,")"),columns = c("Difference Mean","Difference Median","Difference SD")) |>
     tab_spanner(label = str_c("Abs. Difference"," (",unit,")"),columns = c("Absolute Difference Mean","Absolute Difference Median","Absolute Difference SD")) |>
     tab_spanner(label = "Relative Difference(%)",columns = c("Relative Difference(%) Mean","Relative Difference(%) Median","Relative Difference(%) SD")) |>
     tab_spanner(label = "Absolute Relative Difference(%)",columns = c("Absolute Relative Difference(%) Mean","Absolute Relative Difference(%) Median","Absolute Relative Difference(%) SD")) |>
     fmt_number(columns = contains(c("Mean","Median")),decimals = 1) |>
     fmt_number(columns = contains(c("SD")),decimals = 2) |>
     cols_label(
      `Difference Mean` = "Mean",`Difference Median` = "Median",
      `Difference SD` = "SD",
      `Relative Difference(%) Mean` = "Mean",`Relative Difference(%) Median` = "Median",`Relative Difference(%) SD` = "SD",
      `Absolute Difference Mean` = "Mean",`Absolute Difference Median` = "Median",
      `Absolute Difference SD` =  "SD",`Absolute Relative Difference(%) Mean` = "Mean",
      `Absolute Relative Difference(%) Median` = "Median",
      `Absolute Relative Difference(%) SD` = "SD") |>
       sub_missing(columns = everything(),missing_text = "") |>
       opt_stylize(style = 6, color = "blue")
   }
}
```

```{r}
Ap_mmol |>
   select(!contains("Difference")) |> 
   # filter(Day <= 15) |> 
   # filter(between(Gl,40,400)) |> 
   diff_measure_fun(type = "Glucose",breakpoint = 5.6,ref = Reference_mmol, cgm = Gl_mmol, col_subject = `Subject ID` ,group_var = c("Sensor"), unit = "mmol/L",reference_breakpoint = F)
```

```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |> 
   filter(nday <= 15) |> 
   filter(between(cgm_rslt,40,400)) |> 
   diff_measure_fun(type = "Glucose",breakpoint = 80,ref = ref_rslt, cgm = cgm_rslt,col_subject = subjid, group_var = c("age_grp","ref_type"), unit = "mg/dL",reference_breakpoint = T)
```

```{r}
Ap |> 
   select(!c(`Difference(mg/dL)`:`Absolute Relative Difference(%)`)) |> 
   # filter(Day <= 15) |> 
   filter(between(Gl,40,400)) |> 
   diff_measure_fun(type = "Glucose",ref = Reference, cgm = Gl,breakpoint = 100 ,col_subject = `Subject ID`, group_var = c("Age Group","Reference Type"), unit = "mg/dL",reference_breakpoint = T)
```

```{r}
Ap |> 
   select(!c(`Difference(mg/dL)`:`Absolute Relative Difference(%)`)) |> 
   filter(Day <= 15) |> 
   filter(between(Gl,40,400)) |> 
   diff_measure_fun(ref = Reference, cgm = Gl,group_var = c("Age Group","Reference Type","Ref. Glucose Level"), unit = "mg/dL",reference_breakpoint = F) 
```

```{r}
#| label: CGM Difference Measures vs. YSIref
#| tbl-cap: "CGM Difference Measures vs. YSIref"
Ap |> 
   filter(Day <= 15) |> 
   diff_measure_fun(group_var = c(`Age Group`,`Reference Type`,Level),reference = T)
```

```{r}
#| label: CGM Difference Measures by Reference Glucose Level, YSIref
#| tbl-cap: "CGM Difference Measures by Reference Glucose Level, YSIref"
Ap |> 
   filter(Day <= 15) |> 
   diff_measure_fun(group_var = c(`Age Group`,`Reference Type`,`Ref. Glucose Level`),reference = F)
```

```{r}
#| label: CGM Difference Measures by CGM Level, YSIref
#| tbl-cap: "CGM Difference Measures by CGM Level, YSIref"
Ap |> 
   filter(Day <= 15) |> 
   diff_measure_fun(group_var = c(`Age Group`,`Reference Type`,`CGM Glucose Level`),reference = F)
```

<!-- UID -->

```{r}
#| label: Import SA
sa <- haven::read_sas(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-23234\OpenClinica\Current\sa.sas7bdat)"))
```

```{r}
#| label: Import ketone.rds
ketone <- readRDS(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-RES-23234_IDE Pump Suspension Study\Statistics\Programs\Datasets\AL\ketone.rds)"))
```

```{r}
convert_UID_to_sensor_serial_number1 <- function(x){

  lookup <- c(seq(0,9),LETTERS[!str_detect(LETTERS,"B|I|O|S")])

  tibble(UID = x) |>
    # Length should be 16
    filter(str_length(UID) == 16) |>
    # Big O in the sensor serial number
    mutate(UID = str_replace(UID,"O","0")) |>
    separate_wider_position(UID,c(4,binary1 = 2,binary2 = 2,binary3 = 2,binary4 = 2,binary5 = 2,binary6 = 2),cols_remove = F) |>
    # Hex to Binary
    mutate(across(c(binary1:binary6), ~ formatC(as.integer(R.utils::intToBin(strtoi(.x, base = 16))),width = 8, flag = "0")),
           binary = str_c(binary1,binary2,binary3,binary4,binary5,binary6)) |>
    separate_wider_position(binary, c(3,num1 = 5,num2 = 5,num3 = 5,num4 = 5,num5 = 5,num6 = 5,
                                      num7 = 5,num8 = 5,num9 = 5)) |>
    # Binary to integer
    mutate(across(c(num1:num9), ~ strtoi(.x, base = 2) + 1),
           snr = str_c(lookup[num1],lookup[num2],lookup[num3],lookup[num4],
                       lookup[num5],lookup[num6],lookup[num7],lookup[num8],
                       lookup[num9])) |>
    select(!c(contains("binary"),num_range("num",1:9))) |>
    bind_rows(tibble(UID = x) |>
              filter(str_length(UID) != 16 | is.na(UID)) |>
              mutate(snr = UID)) |>
    pull(snr)
}
```

```{r}
sa |> 
   bind_rows(tibble(DUSPID03 = c("E07A0042578134388888","E07A00425781",NA))) |> 
   mutate(snr = UUU::convert_UID_to_sensor_serial_number(DUSPID03)) |> View()
```

```{r}
ketone |>
   filter(Type == "SENSOR_STARTED (58)") |> 
   bind_rows(tibble(`Sensor Serial Number` = c("089CR2EHN555","089CR2E",NA))) |> 
   mutate(UID = UUU::convert_sensor_serial_number_to_UID(`Sensor Serial Number`)) |> View()
```

<!-- System Agreement  -->

```{r}
#| label: Import Ap.rds
Ap <- readRDS(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-VAL-21206 iCGM Libre 2\Statistics\Programs\Canada\Datasets\Ap.rds)"))
```

```{r}
#| label: System Agreement function
system_agreement_fun <- function(data, type = "Glucose", breakpoint = 70, ref, cgm, unit = "mg/dL",group_var, transpose = NULL, wider_name = NULL) {

  data <- data |>
          select(!contains("Difference")) |>
          mutate(
                 # Subject = as.character({{col_subject}}),
                 Difference = {{cgm}} - {{ref}},
                `Absolute Difference` = abs(Difference),
                `Relative Difference(%)` = (Difference/{{ref}})*100,
                `Absolute Relative Difference(%)` = abs(`Relative Difference(%)`))
  
  # Type = Glucose
if (str_detect(type,regex("Glucose",ignore_case = T))){
    glmmol_breaks <- c(0,0.8,1.1,2.2,Inf)
    gl_breaks <- c(0,15,20,40,Inf)
    breakpoint_string <- as.character(breakpoint)
  
# If unit = mg/dL 
if (unit == "mg/dL"){
  sys <- data |> 
         mutate(Level = case_when(round({{ref}} + 0.001) < breakpoint 
                                  ~ str_c("<",breakpoint_string," mg/dL"),
                                  .default = str_c(">=",breakpoint_string," mg/dL"))) |>   
         # Overall 
         bind_rows(data |>
                   mutate(Level = "Overall")) |>
         mutate(Level = factor(Level,levels = c(str_c("<",breakpoint_string," mg/dL"),str_c(">=",breakpoint_string," mg/dL"),"Overall")),
                Group = case_when(round({{ref}} + 0.001) < breakpoint ~ cut(round(`Absolute Difference` + 0.001,0), breaks = gl_breaks,include.lowest = T),
                                  .default = cut(round(`Absolute Relative Difference(%)` + 0.001,0), breaks = gl_breaks,include.lowest = T))) |> 
         # User-defined
          group_by(Level) |> 
          group_by(pick({{group_var}}),.add = T) |>
          count(Level,Group,.drop = F) |>
          mutate(Sum = sum(n),
                 cum = case_when(row_number() %in% c(1:3) ~ cumsum(n),
                      .default = n),
                 Percent = case_when(Sum == 0 ~ 0,
                          .default = round((cum/Sum)*100,1))) |>
         ungroup() |> 
         filter(!is.na(Level))
  
    
  gt_group_var <- group_var[1:length(group_var) - 1]

if (transpose == TRUE) {
 # gt_group_var <- group_var[1:length(group_var) - 1]
 sys |>
   filter(!is.na({{wider_name}})) |>
   mutate(Group = case_when(
          Level == str_c("<",breakpoint_string," mg/dL")
                    & Group == "[0,15]" ~ "Within +- 15 mg/dL [0.8 mmol/L]",
          Level == str_c("<",breakpoint_string," mg/dL")
                    & Group == "(15,20]" ~ "Within +- 20 mg/dL [1.1 mmol/L]",
          Level == str_c("<",breakpoint_string," mg/dL")
                    & Group == "(20,40]" ~ "Within +- 40 mg/dL [2.2 mmol/L]",
          Level == str_c("<",breakpoint_string," mg/dL")
                    & Group == "(40,Inf]" ~ "Outside +- 40 mg/dL [2.2 mmol/L]",
          Level == str_c(">=",breakpoint_string," mg/dL")
                    & Group == "[0,15]" ~ "Within +- 15%",
          Level == str_c(">=",breakpoint_string," mg/dL")
                    & Group == "(15,20]" ~ "Within +- 20%",
          Level == str_c(">=",breakpoint_string," mg/dL")
                    & Group == "(20,40]" ~ "Within +- 40%",
          Level == str_c(">=",breakpoint_string," mg/dL")
                    & Group == "(40,Inf]" ~ "Outside +- 40%",
          Level == "Overall" & Group == "[0,15]" ~ "Within  15 mg/dL or 15%",
          Level == "Overall" & Group == "(15,20]" ~ "Within  20 mg/dL or 20%",
          Level == "Overall" & Group == "(20,40]" ~ "Within  40 mg/dL or 40%",
          Level == "Overall" & Group == "(40,Inf]" ~ "Outside  40 mg/dL or 40%"),
          `N(%)` = str_c(cum,"/",Sum," ","(",Percent,"%)")) |>
    arrange(pick({{group_var}})) |>
    pivot_wider(id_cols = !c(n:Percent),names_from = {{wider_name}},values_from = `N(%)`) |>
    gt(groupname_col = c(gt_group_var,"Level")) |>
    cols_align(align = "center") |>
    sub_missing(columns = everything(),missing_text = "") |>
    opt_stylize(style = 6, color = "blue")

} else {
  # gt_group_var <- group_var[1:length(group_var) - 1]
  sys |>
    mutate(Group = case_when(
           Group == "[0,15]" ~ "Within +- 15% / Within +- 15 mg/dL [0.8 mmol/L]",
           Group == "(15,20]" ~ "Within +- 20% / Within +- 20 mg/dL [1.1 mmol/L]",
           Group == "(20,40]" ~ "Within +- 40% / Within +- 40 mg/dL [2.2 mmol/L]",
           Group == "(40,Inf]" ~ "Outside +- 40%/ Outside +- 40 mg/dL [2.2 mmol/L]"),
          `N(%)` = str_c(cum,"/",Sum," ","(",Percent,"%)")) |>
    arrange(pick({{group_var}})) |>
    pivot_wider(id_cols = !c(n:Percent),names_from = Group,values_from = `N(%)`) |>
    gt(groupname_col = c(gt_group_var,"Level")) |>
    cols_align(align = "center") |>
    cols_width(everything() ~ px(200)) |>
    opt_stylize(style = 6, color = "blue")
  }
}  else if (unit == "mmol/L") {

 sys <- data |>
        mutate(Level = case_when(round({{ref}}*18.016 + 0.001,1) < breakpoint 
                                 ~ str_c("<",breakpoint_string," mg/dL"),
                                 .default = str_c(">=",breakpoint_string," mg/dL"))) |>
        # Overall
        bind_rows(data |>
                  mutate(Level = "Overall")) |>
        mutate(Level = factor(Level,levels = c(str_c("<",breakpoint_string," mg/dL"),str_c(">=",breakpoint_string," mg/dL"),"Overall")),
               Group = case_when(round(Reference + 0.001,1) < 70 ~ cut(round(`Absolute Difference` + 0.001,1), breaks = glmmol_breaks,include.lowest = T),
                                 .default = cut(round(`Absolute Relative Difference(%)` + 0.001,0), breaks = gl_breaks,include.lowest = T)),
               # Combine Groups
               Group = factor(case_when(Group == "[0,0.8]" ~ "[0,15]",
                                        Group == "(0.8,1.1]" ~ "(15,20]",
                                        Group == "(1.1,2.2]" ~ "(20,40]",
                                        Group == "(2.2,Inf]" ~ "(40,Inf]",
                                  .default = Group),levels = c("[0,15]","(15,20]","(20,40]","(40,Inf]"))) |>
            
         group_by(Level) |> 
         # User-defined
         group_by(pick({{group_var}}),.add = T) |>
         count(Level,Group,.drop = F) |>
         mutate(Sum = sum(n),
                cum = case_when(row_number() %in% c(1:3) ~ cumsum(n),
                     .default = n),
                Percent = case_when(Sum == 0 ~ 0,
                         .default = round((cum/Sum)*100,1))) |>
        ungroup() |>
        filter(!is.na(Level))
 
 gt_group_var <- group_var[1:length(group_var) - 1]
 
 if (transpose == TRUE) {
 sys |>
   filter(!is.na({{wider_name}})) |>
   mutate(Group = case_when(
          Level == str_c("<",breakpoint_string," mg/dL") & Group == "[0,15]" ~ "Within  0.8 mmol/L [15 mg/dL]",
          Level == str_c("<",breakpoint_string," mg/dL") & Group == "(15,20]" ~ "Within  1.1 mmol/L [20 mg/dL]",
          Level == str_c("<",breakpoint_string," mg/dL") & Group == "(20,40]" ~ "Within  2.2 mmol/L [40 mg/dL]",
          Level == str_c("<",breakpoint_string," mg/dL") & Group == "(40,Inf]" ~ "Outside  2.2 mmol/L [40 mg/dL]",
          Level == str_c(">=",breakpoint_string," mg/dL") & Group == "[0,15]" ~ "Within  15%",
          Level == str_c(">=",breakpoint_string," mg/dL") & Group == "(15,20]" ~ "Within  20%",
          Level == str_c(">=",breakpoint_string," mg/dL") & Group == "(20,40]" ~ "Within  40%",
          Level == str_c(">=",breakpoint_string," mg/dL") & Group == "(40,Inf]" ~ "Outside  40%",
          Level == "Overall" & Group == "[0,15]" ~ "Within  0.8 mmol/L or 15%",
          Level == "Overall" & Group == "(15,20]" ~ "Within  1.1 mmol or 20%",
          Level == "Overall" & Group == "(20,40]" ~ "Within  2.2 mmol/L or 40%",
          Level == "Overall" & Group == "(40,Inf]" ~ "Outside  2.2 mmol/L or 40%"),
          `N(%)` = str_c(cum,"/",Sum," ","(",Percent,"%)")) |>
    arrange(pick({{group_var}})) |>
    pivot_wider(id_cols = !c(n:Percent),names_from = {{wider_name}},values_from = `N(%)`) |> 
    gt(groupname_col = c(gt_group_var,"Level")) |>
    cols_align(align = "center") |>
    sub_missing(columns = everything(),missing_text = "") |>
    opt_stylize(style = 6, color = "blue")

} else {
  sys |> 
    mutate(Group = case_when(
           Group == "[0,15]" ~ "Within  15% / 15 mg/dL [0.8 mmol/L]",
           Group == "(15,20]" ~ "Within  20% / 20 mg/dL [1.1 mmol/L]",
           Group == "(20,40]" ~ "Within  40% / 40 mg/dL [2.2 mmol/L]",
           Group == "(40,Inf]" ~ "Outside  40%/ 40 mg/dL [2.2 mmol/L]"),
          `N(%)` = str_c(cum,"/",Sum," ","(",Percent,"%)")) |>
    arrange(pick({{group_var}})) |>
    pivot_wider(id_cols = !c(n:Percent),names_from = Group,values_from = `N(%)`) |>    
    gt(groupname_col = c(gt_group_var,"Level")) |>
    cols_align(align = "center") |>
    cols_width(everything() ~ px(200)) |>
    opt_stylize(style = 6, color = "blue")
   }
 }
} else if (str_detect(type,regex("Ketone",ignore_case = T))) {
  ketone_breaks <- c(0,0.1,0.2,0.3,0.4,Inf)
  ketone_breaks_percent <- c(0,10,20,30,40,Inf)
 sys <- data |> 
        mutate(Level = case_when({{ref}} < 1 ~ "< 1 mmol/L",
                                 .default = ">= 1 mmol/L")) |> 
        bind_rows(data |> 
                  mutate(Level = "Overall")) |>   
        mutate(Level = factor(Level,levels = c("< 1 mmol/L",">= 1 mmol/L","Overall")),
               Group = case_when(Level %in% c("< 1 mmol/L","Overall") & {{ref}} < 1 ~ cut(round(`Absolute Difference` + 0.0001,1), breaks = ketone_breaks,include.lowest = T),
                                 Level %in% c(">= 1 mmol/L","Overall") & {{ref}} >= 1 ~ cut(round(`Absolute Relative Difference(%)` + 0.001,0), breaks = ketone_breaks_percent,include.lowest = T)),
               # Modify Overall Group
               Group = case_when(Level == "Overall" & Group == "[0,0.1]" ~ "[0,10]",
                                 Level == "Overall" & Group == "(0.1,0.2]" ~ "(10,20]",
                                 Level == "Overall" & Group == "(0.2,0.3]" ~ "(20,30]",
                                 Level == "Overall" & Group == "(0.3,0.4]" ~ "(30,40]",
                                 Level == "Overall" & Group == "(0.4,Inf]" ~ "(40,Inf]",
                                 .default = Group),
               Group = factor(Group,
                              levels = c("[0,0.1]","(0.1,0.2]","(0.2,0.3]","(0.3,0.4]","(0.4,Inf]"
                                        ,"[0,10]","(10,20]","(20,30]","(30,40]","(40,Inf]"))) |>
          group_by(Level) |>
           # User-defined
          group_by(pick({{group_var}}),.add = T) |>
          count(Level,Group,.drop = F) |>
         # Remove redundant factor levels
         filter(!(Level == "< 1 mmol/L"
                & Group %in% c("[0,10]","(10,20]","(20,30]","(30,40]","(40,Inf]")) &
                !(Level %in% c(">= 1 mmol/L","Overall")
                & Group %in% c("[0,0.1]","(0.1,0.2]","(0.2,0.3]","(0.3,0.4]","(0.4,Inf]"))) |>
          mutate(Sum = sum(n),
                 cum = case_when(row_number() %in% c(1:4) ~ cumsum(n),
                      .default = n),
                 Percent = case_when(Sum == 0 ~ 0,
                          .default = round((cum/Sum)*100,1))) |>
         ungroup() |>
         filter(!is.na(Level))
    
   if (transpose == TRUE){
        gt_group_var <- group_var[1:length(group_var) - 1]
        sys |>
            filter(!is.na({{wider_name}})) |>
            mutate(Group = case_when(
          Level == "< 1 mmol/L" & Group == "[0,0.1]" ~ "Within  0.1 mmol/L",
          Level == "< 1 mmol/L" & Group == "(0.1,0.2]" ~ "Within  0.2 mmol/L",
          Level == "< 1 mmol/L" & Group == "(0.2,0.3]" ~ "Within  0.3 mmol/L",
          Level == "< 1 mmol/L" & Group == "(0.3,0.4]" ~ "Within  0.4 mmol/L",
          Level == "< 1 mmol/L" & Group == "(0.4,Inf]" ~ "Outside  0.4 mmol/L",
          Level == ">= 1 mmol/L" & Group == "[0,10]" ~ "Within  10%",
          Level == ">= 1 mmol/L" & Group == "(10,20]" ~ "Within  20%",
          Level == ">= 1 mmol/L" & Group == "(20,30]" ~ "Within  30%",
          Level == ">= 1 mmol/L" & Group == "(30,40]" ~ "Within  40%",
          Level == ">= 1 mmol/L" & Group == "(40,Inf]" ~ "Outside  40%",
          Level == "Overall" & Group == "[0,10]" ~ "Within  10% / Within  0.1 mmol/L",
          Level == "Overall" & Group == "(10,20]" ~ "Within  20% / Within  0.2 mmol/L",
          Level == "Overall" & Group == "(20,30]" ~ "Within  30% / Within  0.3 mmol/L",
          Level == "Overall" & Group == "(30,40]" ~ "Within  40% / Within  0.4 mmol/L",
          Level == "Overall" & Group == "(40,Inf]" ~ "Outside  40%/ Outside  0.4 mmol/L"),
          `N(%)` = str_c(cum,"/",Sum," ","(",Percent,"%)")) |>
    arrange(pick({{group_var}})) |>
    pivot_wider(id_cols = !c(n:Percent),names_from = {{wider_name}},values_from = `N(%)`) |> 
    gt(groupname_col = c(gt_group_var,"Level")) |>
    cols_align(align = "center") |>
    sub_missing(columns = everything(),missing_text = "") |>
    opt_stylize(style = 6, color = "blue")
    } else {
     gt_group_var <- group_var[1:length(group_var)]

     sys |>
         mutate(Group = case_when(
                Group %in% c("[0,10]","[0,0.1]") ~ "Within  10% / Within  0.1 mmol/L",
                Group %in% c("(10,20]","(0.1,0.2]") ~ "Within  20% / Within  0.2 mmol/L",
                Group %in% c("(20,30]","(0.2,0.3]") ~ "Within  30% / Within  0.3 mmol/L",
                Group %in% c("(30,40]","(0.3,0.4]") ~ "Within  40% / Within  0.4 mmol/L",
                Group %in% c("(40,Inf]","(0.4,Inf]") ~ "Outside  40%/ Outside  0.4 mmol/L"),
                `N(%)` = str_c(cum,"/",Sum," ","(",Percent,"%)")) |>
        arrange(pick({{group_var}})) |>
        pivot_wider(id_cols = !c(n:Percent),names_from = Group,values_from = `N(%)`) |>
        gt(groupname_col = c(gt_group_var)) |>
        cols_align(align = "center") |>
        cols_width(everything() ~ px(200)) |>
        opt_stylize(style = 6, color = "blue")
    }
  
}
  
}
```

```{r}
Ap_ketone <- readRDS("Ap_ketone.rds")
```

```{r}
Ap_ketone |> 
      bind_rows(Ap_ketone |>
                mutate(Site = "Overall")) |>
      mutate(Site = factor(Site, levels = c("Yale","RCR","Overall"))) |>
      filter(between(ANA,0.6,3)) |> 
      system_agreement_fun(type = "Ketone",breakpoint = NULL,ref = KRSEQ01,cgm = ANA, unit = "mmol/L",group_var = c("Site","Ref Type"),transpose = F,wider_name = NULL)
```

```{r}
Ap_ketone |> 
      # bind_rows(Ap_ketone |> 
      #           mutate(Site = "Overall")) |> 
      # mutate(Site = factor(Site, levels = c("Yale","RCR","Overall"))) |> 
      filter(between(ANA,0.6,3)) |> 
      system_agreement_fun(type = "Ketone",wider_name = NULL,ref = KRSEQ01, cgm = ANA, unit = "mmol/L",transpose = F, group_var = c("Site","Ref Type"), breakpoint = 70)
```

```{r}
#| label: Real Time System Accuracy Results Group by Reference Level
#| column: page
Ap_mmol |>
        system_agreement_fun(wider_name = Sensor,ref = Reference_mmol, cgm = Gl_mmol, unit = "mmol/L",transpose = T, group_var = c("Sensor"), breakpoint = 70)
```

```{r}
#| label: Real Time System Accuracy Results Group by Reference Level
#| column: page
Ap_mmol |>
        system_agreement_fun(wider_name = NULL,ref = Reference_mmol, cgm = Gl_mmol, unit = "mmol/L",transpose = F, group_var = c("Sensor","Glucose Level(mg/dL) [mmol/L]"), breakpoint = 70)
```

```{r}
#| label: Real Time System Accuracy Results Group by Reference Level
#| column: page
Ap_mmol |>
        system_agreement_fun(wider_name = NULL,ref = Reference_mmol, cgm = Gl_mmol, unit = "mmol/L",transpose = F, group_var = c("Sensor","Day"), breakpoint = 70)
```

```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |> 
   filter(nday <= 15) |> 
   filter(between(cgm_rslt,40,400)) |> 
   system_agreement_fun(wider_name = ref_type, ref = ref_rslt, cgm = cgm_rslt, transpose = T, group_var = c("age_grp","ref_type"), breakpoint = 70)
```

```{r}
#| label: Number and Percent of Results within Reference Glucose <70 mg/dL
#| tbl-cap: "Number and Percent of Results within Reference Glucose <70 mg/dL"
Ap |> 
   filter(between(Gl,40,400)) |>
   system_agreement_fun(wider_name = `Reference Type`,ref = Reference, cgm = Gl, unit = "mg/dL",transpose = F, group_var = c("Age Group","Reference Type"), breakpoint = 70)
```

```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |> 
   filter(nday <= 15) |> 
   filter(between(cgm_rslt,40,400)) |> 
   system_agreement_fun(wider_name = NULL, ref = ref_rslt, cgm = cgm_rslt, transpose = F, group_var = c("age_grp","ref_type"), breakpoint = 80)
```

```{r}
#| label: Number and Percent of Results within Reference Glucose <80 mg/dL
#| tbl-cap: "Number and Percent of Results within Reference Glucose <80 mg/dL"
Ap |> 
   filter(between(Gl,40,400)) |> 
   system_agreement_fun(wider_name = NULL,transpose = F,ref = Reference, cgm = Gl, group_var = c("Age Group","Reference Type"),breakpoint = 80)
```

```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |>
   mutate(`Ref. Glucose Level` = UUU::fct_case_when(round(ref_rslt + 0.001) < 54 ~ "<54 [3.0]",
                           between(round(ref_rslt + 0.001),54,69) ~ "54 to 69 [3.0-3.8]",
                           between(round(ref_rslt + 0.001),70,180) ~ "70 to 180 [3.9-10.0]",
                           between(round(ref_rslt + 0.001),181,250) ~ "181 to 250 [10.0-13.9]",
                                      TRUE ~ ">250 [13.9]")) |> 
   filter(nday <= 15) |>
   filter(between(cgm_rslt,40,400)) |>
   system_agreement_fun(wider_name = NULL, ref = ref_rslt, cgm = cgm_rslt, transpose = F, group_var = c("age_grp","ref_type","Ref. Glucose Level"), breakpoint = 70)
```

```{r}
#| label: Number and Percent of Results within Reference Glucose by Glucose Level
#| tbl-cap: "Number and Percent of Results within Reference Glucose by Glucose Level"
Ap |> 
   # Add parameter
   # filter(Day <= params$day) |>
   bind_rows(Ap |>
             # filter(Day <= params$day) |>
             mutate(`Ref. Glucose Level` = "Overall",
                    `Ref. Glucose Level` = fct_expand(`Ref. Glucose Level`,"Overall"))) |> 
   filter(between(Gl,40,400)) |>
   system_agreement_fun(wider_name = NULL,transpose = F,ref = Reference, cgm = Gl,group_var = c("Age Group","Reference Type","Ref. Glucose Level"),breakpoint = 70)
```

```{r}
#| label: Number and Percent of Results within Reference Glucose by CGM Level
#| tbl-cap: "Number and Percent of Results within Reference Glucose by CGM Level"
Ap |> 
   bind_rows(Ap |>
             mutate(`CGM Glucose Level` = "Overall",
                    `CGM Glucose Level` = fct_expand(`CGM Glucose Level`,"Overall"))) |>
   filter(between(Gl,40,400)) |>
   system_agreement_fun(wider_name = NULL,transpose = F,ref = Reference, cgm = Gl,group_var = c("Age Group","Reference Type","CGM Glucose Level"),breakpoint = 70)
```

```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |>
   # mutate(`Ref. Glucose Level` = UUU::fct_case_when(round(ref_rslt + 0.001) < 54 ~ "<54 [3.0]",
   #                         between(round(ref_rslt + 0.001),54,69) ~ "54 to 69 [3.0-3.8]",
   #                         between(round(ref_rslt + 0.001),70,180) ~ "70 to 180 [3.9-10.0]",
   #                         between(round(ref_rslt + 0.001),181,250) ~ "181 to 250 [10.0-13.9]",
   #                                    TRUE ~ ">250 [13.9]")) |> 
   filter(nday <= 15) |>
   filter(between(cgm_rslt,40,400)) |>
   system_agreement_fun(wider_name = trt_type, ref = ref_rslt, cgm = cgm_rslt, transpose = T, group_var = c("age_grp","ref_type","trt_type"), breakpoint = 70)
```

```{r}
#| label: System Agreement Results for Real-time CGM by Sensor Lot
#| tbl-cap: "System Agreement Results for Real-time CGM by Sensor Lot"
Ap |> 
   filter(between(Gl,40,400)) |>
   # filter(`Reference Type` == "YSI") |> 
   system_agreement_fun(wider_name = `Insulin Therapy`,transpose = T, ref = Reference, cgm = Gl,group_var = c("Age Group","Reference Type","Insulin Therapy"),breakpoint = 70)
```

```{r}
#| label: System Agreement Results for Real-time CGM by Wear Period
#| tbl-cap: "System Agreement Results for Real-time CGM by Wear Period"
Ap |> 
   filter(between(Gl,40,400)) |>
   # filter(`Reference Type` == "YSI") |> 
   system_agreement_fun(wider_name = NULL,transpose = F, ref = Reference, cgm = Gl, group_var = c("Age Group","Reference Type","Wear Period"),breakpoint = 70)
```

```{r}
#| label: Number and Percent of Results within Reference Glucose on Day 1 by Reference Glucose Level
#| tbl-cap: "Number and Percent of Results within Reference Glucose on Day 1 by Reference Glucose Level"
Ap |>
   filter(Day == 1) |> 
   filter(between(Gl,40,400)) |>
   system_agreement_fun(wider_name = NULL,transpose = F,ref = Reference, cgm = Gl,group_var = c("Age Group","Reference Type","12 Hour Interval","Ref. Glucose Level"),breakpoint = 70) |>
   cols_label(`12 Hour Interval` = "Hour")
```

```{r}
 #  gl_breaks <- c(0,15,20,40,Inf)
 # 
 #  breakpoint_string <- as.character(70)
 #  
 # model_data <-  Ap |> 
 #                filter(between(Gl,40,400)) |> 
 #                # filter(`Reference Type` == "YSI") |> 
 #                mutate(Level = case_when(round(Reference + 0.001) < 70 
 #                                  ~ str_c("<",breakpoint_string," mg/dL"),
 #                                  .default = str_c(">=",breakpoint_string," mg/dL"))) |>   
 #         # Overall 
 #         bind_rows(Ap |>
 #                   filter(between(Gl,40,400)) |>
 #                   # filter(`Reference Type` == "YSI") |>
 #                   mutate(Level = "Overall")) |>
 #         mutate(Level = factor(Level,levels = c(str_c("<",breakpoint_string," mg/dL"),str_c(">=",breakpoint_string," mg/dL"),"Overall")),
 #                Group = case_when(round(Reference + 0.001) < 70 ~ cut(round(`Absolute Difference(mg/dL)` + 0.001,0), breaks = gl_breaks,include.lowest = T),
 #                                  .default = cut(round(`Absolute Relative Difference(%)` + 0.001,0), breaks = gl_breaks,include.lowest = T))) |> 
 #         # User-defined
 #          group_by(pick(c("Age Group","Level","Reference Type","Subject ID"))) |>
 #          count(Level,Group,.drop = F) |>
 #          mutate(Sum = sum(n),
 #                 cum = case_when(row_number() %in% c(1:3) ~ cumsum(n),
 #                      .default = n),
 #                 Percent = case_when(Sum == 0 ~ 0,
 #                          .default = cum/Sum),
 #                 sys = "Libre Primary") |> 
 #          ungroup() |> 
 #          filter(Level == "Overall" & Group == "(20,40]") |> 
 #          filter(`Age Group` == "Ages 18+" , `Reference Type` == "YSI")
```

```{r}
# proc glimmix data=sysacc_sum_subj noitprint;
#  where level2='Combined results';
#  by level2 ref_type event sys;
#  class sys subjid;
#  model n_in40 / n_tot40=sys / link=logit dist=binomial ddfm=satterthwaite noint;
#  random intercept / subject=subjid;
#  lsmeans sys / cl alpha=.2 ilink;
#  ods output lsmeans=outglimmix_90_lcl;
# run;
```

```{r}
# library(lme4)
# library(lsmeans)
# 
# # Fitting the mixed-effects logistic regression model
# model <- glmer(cbind(cum, Sum - cum) ~ 1 + (1 | `Subject ID`),
#                data = model_data,
#                family = binomial(link = "logit"))
# 
# # Calculating LS means
# lsmeans <- lsmeans(model, specs = "sys")
# 
# # Extracting 90% confidence interval for LS means
# lsmeans_ci <- confint(lsmeans, level = 0.9)
# 
# # Printing LS means and 90% confidence interval
# print(lsmeans_ci)
```

<!-- Concurrence -->

```{r}
#| label: Concurrence function
concur_fun <- function(data, bin = c(40,60,80,120,160,200,250,300,350,400), ref, cgm, group_var, trans = FALSE){

      bins <- c(0,bin,Inf)
      lv <- vector("list")
      for (i in 2:length(bins)) {
          if (i == 2){
           lv[[i]] <- c(str_c("<",bins[i]),str_c(bins[i],"-",bins[i+1]))
          }
          else if (i %in% c(3:(length(bins)-2))){
           lv[[i]] <- str_c(bins[i]+1,"-",bins[i+1])
          } 
          else if (i == length(bins)-1) {
           lv[[i]] <- str_c(">",bins[length(bins)-1])
          }
      }

      label <- lv |> 
               list_c()
   
      gt_group_var <- group_var
      
  if (trans == FALSE){
    map2(data |>
          group_split(pick({{group_var}})) |>
          map(\(df) df |> select({{group_var}})) |>
          map(\(df) df |> slice(1:(length(bins)-1))),
          data |>
            # Round half to even, so add noise
          mutate(across(c({{cgm}},{{ref}}), ~ round(.x + 0.0001)),
                 {{ref}} := case_when({{ref}} == bins[2] ~ 
                              cut({{ref}} + 0.001, breaks = bins, right = T,include.lowest = T,
                                    labels = label),
                              .default = cut({{ref}}, breaks = bins, right = T,include.lowest = T,labels = label)),
                 {{cgm}} := case_when({{cgm}} == bins[2] ~ 
                              cut({{cgm}} + 0.001, breaks = bins, right = T,include.lowest = T,
                                    labels = label
                                       ),
                              .default = cut({{cgm}}, breaks = bins, right = T,include.lowest = T,labels = label))) |>
          group_split(pick({{group_var}})) |>
          map(\(df) tabyl(df,{{cgm}},{{ref}})) |> 
          adorn_totals("col") |>
          adorn_percentages("row") |>
          adorn_pct_formatting(digits = 1) |>
          adorn_ns(),bind_cols) |>  
          list_rbind() |>  
          mutate(Total = str_remove_all(Total,"100.0%|\\(|\\)")) |> 
          gt(groupname_col = c(gt_group_var)) |> 
          cols_align(align = "center") |> 
          cols_label({{cgm}} := "CGM (mg/dL)") |> 
          sub_missing(columns = everything(),missing_text = "") |> 
          opt_stylize(style = 6, color = "blue") |>
          tab_spanner(label = "YSI (mg/dL)",columns = !contains("Total")) |>
          tab_header(title = md("Concurrence Analysis by Glucose Level"))
  } else {
     map2(data |>
          group_split(pick({{group_var}})) |>
          map(\(df) df |> select({{group_var}})) |>
          map(\(df) df |> slice(1:(length(bins)-1))),
          data |>
            # Round half to even, so add noise
          mutate(across(c({{cgm}},{{ref}}), ~ round(.x + 0.0001)),
                 {{ref}} := case_when({{ref}} == bins[2] ~ 
                              cut({{ref}} + 0.001, breaks = bins, right = T,include.lowest = T,
                                    labels = label),
                              .default = cut({{ref}}, breaks = bins, right = T,include.lowest = T,labels = label)),
                 {{cgm}} := case_when({{cgm}} == bins[2] ~ 
                              cut({{cgm}} + 0.001, breaks = bins, right = T,include.lowest = T,
                                    labels = label
                                       ),
                              .default = cut({{cgm}}, breaks = bins, right = T,include.lowest = T,labels = label))) |>
          group_split(pick({{group_var}})) |>
          map(\(df) tabyl(df,{{ref}},{{cgm}})) |> 
          adorn_totals("col") |>
          adorn_percentages("row") |>
          adorn_pct_formatting(digits = 1) |>
          adorn_ns(),bind_cols) |>  
          list_rbind() |>  
          mutate(Total = str_remove_all(Total,"100.0%|\\(|\\)")) |> 
          gt(groupname_col = c(gt_group_var)) |> 
          cols_align(align = "center") |> 
          cols_label({{ref}} := "YSI (mg/dL)") |> 
          sub_missing(columns = everything(),missing_text = "") |> 
          opt_stylize(style = 6, color = "blue") |>
          tab_spanner(label = "CGM (mg/dL)",columns = !contains("Total")) |>
          tab_header(title = md("Concurrence Analysis by YSI Glucose Level"))
  }
}
```

```{r}
Ap |>
   filter(`Reference Type` == "YSI") |> 
   UUU::concurrence(bin = c(40,50,60,70,80,90,100,110,120),ref = Reference, cgm = Gl,group_var = c("Age Group"),trans = F) 
```

```{r}
#| label: Concurrence Analysis by Glucose Level
#| tbl-cap: "Concurrence Analysis by Glucose Level"
# bins <- c(40,60,80,120,160,200,250,300,350,400)
Ap |>
   filter(`Reference Type` == "YSI") |> 
   concur_fun(ref = Reference, cgm = Gl,group_var = c("Age Group"),trans = T) 
```

```{r}
#| label: Concurrence Analysis by Glucose Level
#| tbl-cap: "Concurrence Analysis by Glucose Level"
Ap |>
   filter(`Reference Type` == "YSI") |> 
   concur_fun(bin = c(40,50,60,70,80,90,100,110,120),ref = Reference, cgm = Gl,group_var = c("Age Group"),trans = F) 
```

```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |>
  bind_rows(
haven::read_sas("adc21206_paired_ca_orr.sas7bdat")) |> 
   filter(nday <= 15) |> 
   filter(ref_type == "YSI") |> 
   concur_fun(bin = c(40,50,60,70,80,90,100,110,120),ref = ref_rslt, cgm = cgm_rslt,group_var = c("age_grp"),trans = F)
```

```{r}
Ap206 <- haven::read_sas(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-VAL-21206 iCGM Libre 2\Statistics\Programs\Datasets\adc21206_paired_us.sas7bdat)")) |> 
      bind_rows(
        haven::read_sas(gsub("\\\\", "/", r"(\\oneabbott.com\dept\ADC\Technical_OPS\Clinical_Affairs\Clinical Study Files\Apollo\ADC-US-VAL-21206 iCGM Libre 2\Statistics\Programs\Datasets\adc21206_paired_us_orr.sas7bdat)"))
      )
```

```{r}
# bins <- c(40,50,60,70,80,120,150,180,200)
Ap206 |>
      filter(nday <= 14) |>
      filter(ref_type == "YSI") |> 
      concur_fun(bin = c(55,70,90,120,160,200),ref = ref_rslt, cgm = cgm_rslt,group_var = c("age_grp"),trans = F)
```

```{r}
#| label: Concurrence Analysis by Glucose Level in Low Range
#| tbl-cap: "Concurrence Analysis by Glucose Level in Low Range"
Ap |>
   filter(`Reference Type` == "YSI") |> 
   concur_fun(bin = c(0,seq(40,120,10),Inf),ref = Reference, cgm = Gl,group_var = c("Age Group"),trans = F) |> 
   tab_header(title = md("Concurrence Analysis by Glucose Level in Low Range"))
```

```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |>
  bind_rows(
haven::read_sas("adc21206_paired_ca_orr.sas7bdat")) |> 
   filter(nday <= 15) |> 
   filter(ref_type == "YSI") |> 
   concur_fun(bin = c(0,seq(40,120,10),Inf),ref = ref_rslt, cgm = cgm_rslt,group_var = c("age_grp"),trans = F)
```

```{r}
#| label: Concurrence Analysis by YSI Glucose Level
#| tbl-cap: "Concurrence Analysis by YSI Glucose Level"
Ap |>
   filter(`Reference Type` == "YSI") |>
   concur_fun(bin = bins,ref = Reference, cgm = Gl,group_var = c("Age Group"),trans = T)
```

```{r}
haven::read_sas("adc21206_paired_us.sas7bdat") |>
  bind_rows(
haven::read_sas("adc21206_paired_us_orr.sas7bdat")) |>
    filter(nday <= 14) |> 
    filter(ref_type == "YSI") |> 
    concur_fun(bin = c(0,55,70,90,120,160,200,Inf),ref = ref_rslt, cgm = cgm_rslt,group_var = c("age_grp"),trans = T)
```

<!-- ketone.csv -->
```{r}
#| label: Import ketone.csv
#| eval: false
# file_list_ketone <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-22225\SE46_47_48_Ket\Upload Data\UUU\UUU_DataFiles)"),recurse = T, regexp = "*ketone[.]csv$") |> 
#              path_filter(regexp = "Transfer", invert = T, ignore.case = T)
file_list_ketone <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-22225\SE43_44_Ket\UploadData\UUU\UUU_DataFiles)"),recurse = T, regexp = "*ketone[.]csv$") |> 
             path_filter(regexp = "Transfer", invert = T, ignore.case = T)
```

```{r}
ketone <- function(ketone_path, index = NULL){
  # # Individual File
  if (is.numeric(index)) {
    ketone_path[index] |> 
       purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_select = c(`Unique Record ID`,Date,Time,`Ketone Reading`,Status)),tibble::tibble()),.progress = TRUE) |>
      purrr::map(\(df) df |>
            dplyr::transmute(`Subject ID` =
                    dplyr::case_when(
                        # Site ID == ADC
                      stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T)),
                        # Site ID == 009
                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                        # Site ID starts with 1
                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                        # Site ID == 081
                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                        # Site ID mislabeled
                        .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                      ),
         Visit = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
        `Ketone Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
         Reference = `Ketone Reading`,
         Status = Status
        ),.progress = TRUE) |>
      purrr::map(\(df) df |> filter(!is.na(`Ketone Date Time`)),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Filter Status == 0
      dplyr::filter(Status == 0) |>
      # Calculate Average ketone reading if time stamp are same.
      dplyr::mutate(Reference = mean(Reference),
             .by = c(`Subject ID`,`Ketone Date Time`)) |>
      # Remove Duplicated
      dplyr::distinct() |>
      # select Useful Columns
      dplyr::select(!Status) |>
      dplyr::arrange(`Subject ID`,Visit,`Ketone Date Time`)
  } else {
      # All Upload Data
    ketone_path |> 
       purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_select = c(`Unique Record ID`,Date,Time,`Ketone Reading`,Status)),tibble::tibble()),.progress = TRUE) |>
      purrr::map(\(df) df |>
            dplyr::transmute(`Subject ID` =
                    dplyr::case_when(
                        # Site ID == ADC
                      stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T)),
                        # Site ID == 009
                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                        # Site ID starts with 1
                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                        stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                        # Site ID == 081
                      stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                        # Site ID mislabeled
                        .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                      ),
         Visit = stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T)),
        `Ketone Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
         Reference = `Ketone Reading`,
         Status = Status
        ),.progress = TRUE) |>
      purrr::map(\(df) df |> filter(!is.na(`Ketone Date Time`)),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Filter Status == 0
      dplyr::filter(Status == 0) |>
      # Calculate Average ketone reading if time stamp are same.
      dplyr::mutate(Reference = mean(Reference),
             .by = c(`Subject ID`,`Ketone Date Time`)) |>
      # Remove Duplicated
      dplyr::distinct() |>
      # select Useful Columns
      dplyr::select(!Status) |>
      dplyr::arrange(`Subject ID`, Visit,`Ketone Date Time`)
    }
}
```

```{r}
#| warning: false
ketone(ketone_path = file_list_ketone) |> View()
```

```{r}
#| eval: false 
file_list <- dir_ls(recurse = T, regexp = "Clarity") |> 
             path_filter(regexp = "Transfers|Archive", invert = T, ignore.case = T)
```

```{r}
#| label: Import freestyle.csv and clarity
#| eval: false
file_list1 <- dir_ls(gsub("\\\\", "/", r"(\\wf00168p.oneabbott.com\data1\CDM\ADC-US-RES-23241\SE04\UploadData)"),recurse = T, regexp = "Clarity") |> 
             path_filter(regexp = "Transfer|Archive", invert = T, ignore.case = T)
```

```{r}
#| eval: false 
#| warning: false
dexcom_fun <- function(dexcom_path, index = NULL){

if(is.numeric(index)){  
c(dexcom_path[index] |> 
   path_filter(regexp = "Clarity",ignore.case = T) |> 
   path_filter(regexp = "csv",ignore.case = T) |> 
   set_names() |> 
   map(\(path) vroom::vroom(path,show_col_types = F, col_select = c(`Timestamp (YYYY-MM-DDThh:mm:ss)`
                            ,`Event Type`,`Patient Info`,`Glucose Value (mg/dL)`),col_types = c(`Glucose Value (mg/dL)` = "d")),.progress = T),
   # xlsx
   dexcom_path[index] |> 
   path_filter(regexp = "Clarity",ignore.case = T) |> 
   path_filter(regexp = "xlsx",ignore.case = T) |> 
   set_names() |> 
   map(\(path) readxl::read_excel(path),.progress = T) |> 
   map(\(df) df |> dplyr::transmute(`Timestamp (YYYY-MM-DDThh:mm:ss)` = ymd_hms(`Timestamp (YYYY-MM-DDThh:mm:ss)`),
                                   `Event Type` = `Event Type`,
                                   `Patient Info` = as.character(`Patient Info`),
                                   `Glucose Value (mg/dL)` = as.numeric(`Glucose Value (mg/dL)`)
                                ),.progress = T)) |> 
  map(\(df) df |> dplyr::mutate(`Patient Info` = str_remove(`Patient Info`,"^0+")),.progress = T)  |>
  map(\(df) df |> transmute(`Subject ID` = case_when(
                             str_length(df[1,3]) == 1 ~ str_c(df[2,3],"000",df[1,3]),
                             str_length(df[1,3]) == 2 ~ str_c(df[2,3],"00",df[1,3]),
                             .default = str_c(df[2,3],df[1,3])),
                            `Date Time` = `Timestamp (YYYY-MM-DDThh:mm:ss)`,
                             Type = `Event Type`,
                             Gl = `Glucose Value (mg/dL)`),.progress = T) |>
  list_rbind(names_to = "Path") |>
  dplyr::mutate(`Condition ID` = str_extract(Path,regex("[:alpha:]{3}(?=_[:digit:]{4}-[:digit:]{2}-[:digit:]{2})")),.before = `Date Time`) |>
  filter(Type == "EGV") |> 
  arrange(`Subject ID`)
} else {
  c(dexcom_path |> 
    path_filter(regexp = "Clarity",ignore.case = T) |> 
    path_filter(regexp = "csv",ignore.case = T) |> 
    set_names() |> 
    map(\(path) vroom::vroom(path,show_col_types = F, col_select = c(`Timestamp (YYYY-MM-DDThh:mm:ss)`
                            ,`Event Type`,`Patient Info`,`Glucose Value (mg/dL)`),col_types = c(`Glucose Value (mg/dL)` = "d")),.progress = T),
   # xlsx
   dexcom_path |> 
   path_filter(regexp = "Clarity",ignore.case = T) |> 
   path_filter(regexp = "xlsx",ignore.case = T) |> 
   set_names() |> 
   map(\(path) readxl::read_excel(path),.progress = T) |> 
   map(\(df) df |> dplyr::transmute(`Timestamp (YYYY-MM-DDThh:mm:ss)` = ymd_hms(`Timestamp (YYYY-MM-DDThh:mm:ss)`),
                                   `Event Type` = `Event Type`,
                                   `Patient Info` = as.character(`Patient Info`),
                                   `Glucose Value (mg/dL)` = as.numeric(`Glucose Value (mg/dL)`)
                                ),.progress = T)) |> 
  map(\(df) df |> dplyr::mutate(`Patient Info` = str_remove(`Patient Info`,"^0+")),.progress = T)  |>
  map(\(df) df |> transmute(`Subject ID` = case_when(
                             str_length(df[1,3]) == 1 ~ str_c(df[2,3],"000",df[1,3]),
                             str_length(df[1,3]) == 2 ~ str_c(df[2,3],"00",df[1,3]),
                             .default = str_c(df[2,3],df[1,3])),
                            `Date Time` = `Timestamp (YYYY-MM-DDThh:mm:ss)`,
                             Type = `Event Type`,
                             Gl = `Glucose Value (mg/dL)`),.progress = T) |>
  list_rbind(names_to = "Path") |>
  dplyr::mutate(`Condition ID` = str_extract(Path,regex("[:alpha:]{3}(?=_[:digit:]{4}-[:digit:]{2}-[:digit:]{2})")),.before = `Date Time`) |>
  filter(Type == "EGV") |> 
  arrange(`Subject ID`)
}
}
```

```{r}
#| warning: false
dexcom_fun(dexcom_path = file_list) |> View()
```

```{r eval = params$analysis}
#| label: Error Grid Function
error_grid_plot <- function (df, ref, cgm, unit = "gram", group_var = NULL,
                             show_plot = FALSE, title = "", xlab = "", ylab = "")
{
    data1 <- df |> 
             mutate(ref = {{ref}},
                    test = {{cgm}})
    
  # if (type != 1 & type != 2) {
  #   stop("'type' must be 1 or 2.")
  # }
  if (unit != "mol" & unit != "gram") {
    stop("'unit' must be either 'mol' or 'gram'.")
  }
  if (title == "") {
    title <- "Consensus Error Grid"
  }
  if (unit == "mol") {
    n <- 18.016
    if (xlab == "") {
      xlab = "Reference Glucose Concentration (mmol/L)"
    }
    if (ylab == "") {
      ylab = "Test Glucose Concentration (mmol/L)"
    }
  }
  else {
    n <- 1
    if (xlab == "") {
      xlab = "Reference Glucose Concentration (mg/dL)"
    }
    if (ylab == "") {
      ylab = "Test Glucose Concentration (mg/dL)"
    }
  }
 
  zones <- getParkesZones(data1$ref, data1$test, type = 1, unit)
  
  ref <- test <- NULL
  
  data <- data1 |> 
          mutate(Zones = zones)
  
  maxX <- max(max(data$ref) + 20/n, 550/n)
  maxY <- max(max(data$test) + 20/n, 550/n)
  labels <- data.frame(x = c(450, 220/n, 385/n, 140/n, 405/n,
                             415/n, 75/n, 21/n),
                       y = c(450, 360/n, 235/n, 375/n,145/n,
                             50/n, 383/n, 383/n),
        label = c("A", "B","B", "C", "C", "D", "D","E"),
        color = c("gray30", "gray30", "gray30","gray30", "gray30", "gray30", "gray30", "gray30"))

    ce <- ega:::.coef(35, 155, 50, 550)
    cdu <- ega:::.coef(80, 215, 125, 550)
    cdl <- ega:::.coef(250, 40, 550, 150)
    ccu <- ega:::.coef(70, 110, 260, 550)
    ccl <- ega:::.coef(260, 130, 550, 250)
    cbu <- ega:::.coef(280, 380, 430, 550)
    cbl <- ega:::.coef(385, 300, 550, 450)
    x1 <- y1 <- xend <- yend <- NULL
    border <- data.frame(x1 = c(0/n, 0/n, 30/n, 140/n, 280/n,
                                50/n, 50/n, 170/n, 385/n, 0/n, 30/n, 50/n, 70/n,
                                120/n, 120/n, 260/n, 0/n, 25/n, 50/n, 80/n, 250/n,
                                250/n, 0/n, 35/n),
                         y1 = c(0/n, 50/n, 50/n, 170/n,
                                380/n, 0/n, 30/n, 145/n, 300/n, 60/n, 60/n, 80/n,
                                110/n, 0/n, 30/n, 130/n, 100/n, 100/n, 125/n, 215/n,
                                0/n, 40/n, 150/n, 155/n),
                         xend = c(min(maxX, maxY),
                                  30/n, 140/n, 280/n,
                                  ega:::.endx(280/n, 380/n, maxY, cbu),
                                  50/n, 170/n, 385/n, maxX, 30/n, 50/n, 70/n,
                                  ega:::.endx(70/n,110/n, maxY, ccu),
                                  120/n, 260/n, maxX, 25/n,50/n, 80/n,
                                  ega:::.endx(80/n, 215/n, maxY, cdu), 250/n,
                                  maxX, 35/n, ega:::.endx(35/n, 155/n, maxY, ce)),
                         yend = c(min(maxX,maxY), 50/n, 170/n, 380/n, maxY, 30/n, 145/n, 300/n,
                                  ega:::.endy(385/n, 300/n, maxX, cbl), 60/n, 80/n, 110/n,
                                  maxY, 30/n, 130/n, ega:::.endy(260/n, 130/n, maxX, ccl),
                                  100/n, 125/n, 215/n, maxY, 40/n, ega:::.endy(410/n, 110/n,
                                  maxX, cdl), 155/n, maxY))
  
  # else {
  #   ce <- ega:::.coef(35, 200, 50, 550)
  #   cdu <- ega:::.coef(35, 90, 125, 550)
  #   cdl <- ega:::.coef(410, 110, 550, 160)
  #   ccu <- ega:::.coef(30, 60, 280, 550)
  #   ccl <- ega:::.coef(260, 130, 550, 250)
  #   cbu <- ega:::.coef(230, 330, 440, 550)
  #   cbl <- ega:::.coef(330, 230, 550, 450)
  #   border <- data.frame(x1 = c(0/n, 0/n, 30/n, 230/n, 50/n,
  #                               50/n, 90/n, 330/n, 0/n, 30/n, 90/n, 260/n, 0/n, 25/n,
  #                               35/n, 250/n, 250/n, 410/n, 0/n, 35/n),
  #                        y1 = c(0/n,50/n, 50/n, 330/n, 0/n, 30/n, 80/n, 230/n, 60/n,
  #                               60/n, 0/n, 130/n, 80/n, 80/n, 90/n, 0/n, 40/n, 110/n,
  #                               200/n, 200/n),
  #                        xend = c(min(maxX, maxY), 30/n, 230/n,
  #                                 ega:::.endx(230/n, 330/n, maxY, cbu), 50/n, 90/n, 330/n,
  #                                 maxX, 30/n, ega:::.endx(30/n, 60/n, maxY, ccu), 260/n,
  #                                 maxX, 25/n, 35/n, ega:::.endx(35/n, 90/n, maxY, cdu), 250/n,
  #                                 410/n, maxX, 35/n, ega:::.endx(35/n, 200/n, maxY, ce)),
  #                        yend = c(min(maxX, maxY), 50/n, 330/n, maxY, 30/n,
  #                                 80/n, 230/n, ega:::.endy(330/n, 230/n, maxX, cbl),
  #                                 60/n, maxY, 130/n, ega:::.endy(260/n, 130/n, maxX,ccl),
  #                                 80/n, 90/n, maxY, 40/n, 110/n, ega:::.endy(410/n,110/n,
  #                                 maxX, cdl), 200/n, maxY))
  # }

if (show_plot == TRUE) {
plot <- ggplot(data, aes(x = ref, y = test)) +
         scale_x_continuous(breaks = c(0,round(70/n,digits = 1), round(100/n, digits = 1), round(150/n, digits = 1),round(180/n, digits = 1), round(240/n, digits = 1), round(300/n,
         digits = 1), round(350/n, digits = 1), round(400/n,digits = 1), round(450/n, digits = 1), round(500/n,digits = 1), round(550/n, digits = 1), round(600/n,digits = 1), round(650/n, digits = 1), round(700/n,digits = 1), round(750/n, digits = 1), round(800/n,digits = 1), round(850/n, digits = 1), round(900/n,digits = 1), round(950/n, digits = 1), round(1000/n, digits = 1)), expand = c(0, 0)) +
         scale_y_continuous(breaks = c(0,round(70/n, digits = 1), round(100/n, digits = 1), round(150/n, digits = 1),round(180/n, digits = 1), round(240/n, digits = 1), round(300/n,digits = 1), round(350/n, digits = 1), round(400/n,digits = 1), round(450/n, digits = 1), round(500/n,digits = 1), round(550/n, digits = 1), round(600/n,digits = 1), round(650/n, digits = 1), round(700/n, digits = 1), round(750/n, digits = 1), round(800/n, digits = 1),round(850/n,digits = 1), round(900/n,digits = 1), round(950/n, digits = 1), round(1000/n, digits = 1)), expand = c(0, 0)) + 
    geom_point(size = 1, alpha = 0.6) +
    geom_segment(aes(x = x1,y = y1, xend = xend, yend = yend), data = border, linetype = "solid") +
    geom_text(data = labels, aes(x = x, y = y, label = label)) +
    theme_bw() +
    theme(panel.background = element_rect(fill = "white",
                                          colour = "black",
                                          linewidth = 0.5, linetype = "solid"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.line = element_line(linewidth = 0.5, linetype = "solid",colour = "black"),
          legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
           # legend.position="none",
          legend.title = element_blank(),
          legend.text = element_text(size = 12),
          axis.title = element_text(size = 14),
          axis.text = element_text(size = 8),
          aspect.ratio = 1) +
    ggtitle(title) +
    xlab(xlab) +
    ylab(ylab) 
  if (unit == "gram"){
     plot
  } else if (unit == "mol"){
     plot +
     coord_cartesian(xlim = c(0,30.0), ylim = c(0,30.0))
  }
  
    # scale_fill_manual(values = c("1"="grey80","2"="grey30","3"="deepskyblue",
    #                              "4"="greenyellow","5"="tan1","6"="purple"))
} else {
     data
     # gt_group_var <- group_var
     #  map2(data |>
     #       group_split(pick({{group_var}})) |>
     #       map(\(df) df |> select({{group_var}})) |>
     #       map(\(df) df |> slice(1:5)),
     # 
     # data |> 
     # mutate(Zones = factor(Zones,levels = c("A","B","C","D"))) |> 
     # group_split(pick({{group_var}})) |>  
     # map(\(df) tabyl(df, Zones)) |>  
     # map(\(df) df |> adorn_totals("row")) |> 
     # map(\(df) df |> adorn_pct_formatting(digits = 1)),bind_cols) |> 
     # list_rbind() |> 
     # arrange(pick({{group_var}})) |> 
     # gt(groupname_col = c(gt_group_var)) |>
     # cols_align(align = "center",columns = everything()) |>
     # cols_label(n = "N", percent = "Percent") |> 
     # opt_stylize(style = 6, color = "blue")
  }
  
}
```
 <!-- https://github.com/cran/ega/blob/master/R/ega.R -->
```{r}
a <- Ap |> 
   filter(between(Gl,40,400)) |> 
   filter(`Age Group` == "Ages 18+")
```
 
```{r}
getParkesZones(a$Reference, a$Gl, type = 1, "gram")
```
 
```{r}
haven::read_sas("s241_01_paired.sas7bdat") |> 
       error_grid_plot(ref_rslt, cgm_rslt, show_plot = F ,title = "Error Grid Plot", 
                     xlab = "BG555555 Reference (mg/dL)", ylab = "Glucose Result (mg/dL)",unit = "mol")
```

```{r}
haven::read_sas("pk_tab.sas7bdat") |>
  transmute(`Subject ID` = as.character(subjid),
            `Date Time` = ymd_hms(dtm_sec),
            `BG Date Time` = ymd_hms(fs_dtm),
            `Reference Type` = ref_type,
             Gl = cgm_rslt,
             Reference = ref_rslt,
             Zones = parkes) |> 
   arrange(`Subject ID`) |> View()
  # count(ref_type,parkes)
```

```{r}
Ap |> 
   filter(between(Gl,40,400)) |> 
   filter(`Age Group` == "Ages 18+") |> 
   error_grid_plot(Reference, Gl, show_plot = F, title = "Error Grid Plot", 
                   xlab = "BG Reference (mg/dL)", ylab = "Glucose Result (mg/dL)") |> 
   select(`Subject ID`, `Date Time`, `BG Date Time`, `Reference Type`, Gl, Reference, Zones) |> 
   


    count(`Reference Type`, Zones)
```

```{r}
haven::read_sas("pk_tab.sas7bdat") |>
  transmute(`Subject ID` = as.character(subjid),
            `Date Time` = ymd_hms(dtm_sec),
            `BG Date Time` = ymd_hms(fs_dtm),
            `Reference Type` = ref_type,
             Gl = as.character(cgm_rslt),
             Reference = as.character(ref_rslt),
             Zones = parkes) |> 
   arrange(`Subject ID`) |> 
   dplyr::setdiff(
     Ap |> 
   filter(between(Gl,40,400)) |> 
   filter(`Age Group` == "Ages 18+") |> 
   error_grid_plot(Reference, Gl, show_plot = F, title = "Error Grid Plot", 
                   xlab = "BG Reference (mg/dL)", ylab = "Glucose Result (mg/dL)") |> 
   mutate(Gl = as.character(Gl), Reference = as.character(Reference)) |> 
   select(`Subject ID`, `Date Time`, `BG Date Time`, `Reference Type`, Gl, Reference, Zones)
   ) |> 
   arrange(`Subject ID`) |> View()

Ap |> 
   filter(between(Gl,40,400)) |> 
   filter(`Age Group` == "Ages 18+") |> 
   error_grid_plot(Reference, Gl, show_plot = F, title = "Error Grid Plot", 
                   xlab = "BG Reference (mg/dL)", ylab = "Glucose Result (mg/dL)") |> 
   mutate(Gl = as.character(Gl), Reference = as.character(Reference)) |>
   select(`Subject ID`, `Date Time`, `BG Date Time`, `Reference Type`, Gl, Reference, Zones) |> 
   dplyr::setdiff(
     haven::read_sas("pk_tab.sas7bdat") |>
  transmute(`Subject ID` = as.character(subjid),
            `Date Time` = ymd_hms(dtm_sec),
            `BG Date Time` = ymd_hms(fs_dtm),
            `Reference Type` = ref_type,
             Gl = as.character(cgm_rslt),
             Reference = as.character(ref_rslt),
             Zones = parkes) |> 
   arrange(`Subject ID`)
   ) |> 
   arrange(`Subject ID`)

```

```{r}
readRDS("Ap_SE01.rds") |> 
     UUU::consensus_error_grid(Reference_mmol, Gl, show_plot = T,group_var = c("Sensor","Reference Type") ,title = "Error Grid Plot", 
                     xlab = "BG Reference (mg/dL)", ylab = "Glucose Result (mg/dL)",unit = "mol")
     # error_grid_plot(Reference_mmol, Gl, show_plot = F,group_var = c("Sensor","Reference Type") ,title = "Error Grid Plot", 
     #                 xlab = "BG Reference (mg/dL)", ylab = "Glucose Result (mg/dL)",unit = "mol")  
```
 
```{r}
haven::read_sas("adc21206_paired_ca.sas7bdat") |> 
   filter(nday <= 15) |> 
   filter(between(cgm_rslt,40,400)) |> 
   filter(age_grp == "3. 18+") |>
   error_grid_plot(ref_rslt, cgm_rslt,group_var = c("age_grp","ref_type","site") ,show_plot = F, 
                   title = "Error Grid Plot", 
                   xlab = "BG Reference (mg/dL)", ylab = "Glucose Result (mg/dL)") 
```
 
```{r}
#| label: Error Grid Plot
#| fig-align: center
Ap |> 
   filter(between(Gl,40,400)) |> 
   filter(`Age Group` == "Ages 18+" & `Reference Type` == "YSI") |> 
   error_grid_plot(Reference, Gl, show_plot = F, title = "Error Grid Plot", 
                   xlab = "BG Reference (mg/dL)", ylab = "Glucose Result (mg/dL)")  
   # facet_grid(cols = vars(`Reference Type`),switch = "y") + 
   # geom_point(aes(color = `Type of Diabetes`))
```

```{r}
Ap |> 
   filter(between(Gl,40,400)) |> 
   filter(`Age Group` == "Ages 18+" & `Reference Type` == "YSI") |> 
   error_grid_plot(Reference, Gl,group_var = c("Reference Type","Age Group"),show_plot = F)    
   # mutate(Zones = factor(Zones,levels = c("A","B","C","D"))) |>
   # tabyl(Zones,`Reference Type`,`Age Group`) |>
   # map(\(df) df |> adorn_totals("row")) |>
   # map(\(df) df |> adorn_percentages("col")) |>
   # map(\(df) df |> adorn_pct_formatting(digits = 1)) |>
   # map(\(df) df |> adorn_ns()) |>
   # list_rbind(names_to = "Age Group") |>
   # gt(groupname_col = "Age Group") |>
   # cols_align(align = "center",columns = everything()) |>
   # text_replace(pattern = "- \\(0\\)", replacement = "",locations = cells_body(columns = everything())) |>
   # opt_stylize(style = 6, color = "blue")
```

```{r}
Ap |> 
   filter(between(Gl,40,400)) |> 
   filter(`Age Group` == "Ages 18+" & `Reference Type` == "YSI") |> 
   UUU::consensus_error_grid(ref = Reference,cgm = Gl, unit = "gram",show_plot = T)
```


```{r}
# UD <- Ap |> 
#       distinct(`Age Group`,`Reference Type`) |> 
#       arrange(`Age Group`,desc(`Reference Type`))
```

```{r}
#| label: Error Grid Plot
#| fig-align: center
# plots <- vector("list",nrow(UD))
# for (i in 1:nrow(UD)) {
#   plots[[i]] <- Ap |> 
#                 filter(Day <= 15) |> 
#                 filter(between(Gl,40,400) & 
#                       `Age Group` == UD$`Age Group`[i] & 
#                       `Reference Type` == UD$`Reference Type`[i]) |> 
#                 error_grid_plot(Reference, Gl,
#                                 show_plot = T,
#                                 title = str_c("Real-Time Glucose (",UD$`Age Group`[i],")"), 
#                                 xlab = str_c(UD$`Reference Type`[i]," Reference (mg/dL)"),
#                                 ylab = "Glucose Result (mg/dL)", unit = "gram")
#   plots[[i]] |> 
#     print()
# }
```

```{r}
#| label: Import events.csv and anaPlus.csv
#| eval: false
file_list <- dir_ls(gsub("\\\\", "/", r"(C:\UDP\OutputFiles)"), 
                    regexp = "*events.csv|*anaPlus.csv|*oneMinutes.csv", recurse = T) |> 
             path_filter(regexp = "Transfers|Transfer|Archive|Archives|LifeCount", invert = T, ignore.case = T)
```

```{r}
oneminutes <- function(events, one_minutes, index = NULL) {

  # Individual File
  if (is.numeric(index)) {
    purrr::map2(
      # First List
      # Import Events
      events[index] |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),

      purrr::map2(
        # Import oneminutes.csv
        one_minutes[index] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,TXS,Rw,TpSk,Dq,TpBd),n_max = 2),tibble::tibble()),.progress = TRUE),
        one_minutes[index] |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:9),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","TXS","Rw","TpSk","Dq","TpBd"),colClasses = c("V2" = "Date","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                                  dplyr::case_when(
                                                    # Site ID == ADC
                                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                                    # Site ID == 009
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID starts with 1
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID == 081 or 057
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                                    # Site ID mislabeled
                                                    .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                                  ),
                                                `Condition ID` = stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T))),
                                                `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                                Type = Type,
                                                TXS = TXS,
                                                Rw = Rw,
                                                TpSk = TpSk,
                                                Dq = Dq,
                                                TpBd = TpBd),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                                             `Date Time`,Type,TXS,Rw,TpSk,Dq,TpBd),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      suppressWarnings()

  } else {
    # All upload data
    # First List
    # Import Events
    purrr::map2(
      events |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),

      purrr::map2(
        # Import oneminutes.csv
        one_minutes |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,TXS,Rw,TpSk,Dq,TpBd),n_max = 2),tibble::tibble()),.progress = TRUE),
        one_minutes |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:9),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","TXS","Rw","TpSk","Dq","TpBd"),colClasses = c("V2" = "Date","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                                  dplyr::case_when(
                                                    # Site ID == ADC
                                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                                    # Site ID == 009
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID starts with 1
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID == 081 or 057
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                                    # Site ID mislabeled
                                                    .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                                  ),
                                                `Condition ID` = stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T))),
                                                `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                                Type = Type,
                                                TXS = TXS,
                                                Rw = Rw,
                                                TpSk = TpSk,
                                                Dq = Dq,
                                                TpBd = TpBd),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                                             `Date Time`,Type,TXS,Rw,TpSk,Dq,TpBd),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      # dplyr::distinct() |>
      dplyr::arrange(Path,`Subject ID`,`Condition ID`,`Date Time`) |>
      suppressWarnings()
  }
}
```

```{r}
oneminutes <- function(events, one_minutes, index = NULL) {
  
    # Check packages
  packages <- c("tidyverse","data.table","rlang","vroom")
  for (package_name in packages) {
    if (!require(package_name, character.only = TRUE)) {
      install <- readline(prompt = paste("Package", package_name, "is not installed. Do you want to install it? (Yes/No): "))
      # If say yes
      if (tolower(install) == "yes") {
        install.packages(package_name)
        library(package_name, character.only = TRUE)
        message(paste("Package", package_name, "has been installed and loaded."))
      }
       # If say no
       else {
        message(paste("Package", package_name, "was not installed."))
      }
    }
    #   else {
    #   message(paste("Package", package_name, "is already installed and loaded."))
    # }
  }
  
  
  
  if (length(events) != length(one_minutes)) {rlang::abort("Number of devices.csv is not equal to number of readings.csv!")}
  
  if (!is.numeric(index) && !is.null(index)) {rlang::abort("Index must be numeric!")}
  
  # Individual File
  if (is.numeric(index)) {
    
    if (index > length(events) || index > length(one_minutes)) {rlang::abort("Index beyond the range!")}
    
    else {
    purrr::map2(
      # First List
      # Import Events
      events[index] |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),
      
      purrr::map2(
        # Import oneminutes.csv
        one_minutes[index] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,TXS,Rw,TpSk,Dq,TpBd),n_max = 2),tibble::tibble()),.progress = TRUE),
        one_minutes[index] |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:9),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","TXS","Rw","TpSk","Dq","TpBd"),colClasses = c("V2" = "Date","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                                  dplyr::case_when(
                                                    # Site ID == ADC
                                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                                    # Site ID == 009
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID starts with 1
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID == 081 or 057
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                                    # Site ID mislabeled
                                                    .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                                  ),
                                                `Condition ID` = stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T))),
                                                `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                                Type = Type,
                                                TXS = TXS,
                                                Rw = Rw,
                                                TpSk = TpSk,
                                                Dq = Dq,
                                                TpBd = TpBd),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                                             `Date Time`,Type,TXS,Rw,TpSk,Dq,TpBd),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      suppressWarnings()
    }
    
  } else if (is.null(index)){
    # All upload data
    # First List
    # Import Events
    purrr::map2(
      events |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),
      
      purrr::map2(
        # Import oneminutes.csv
        one_minutes |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,TXS,Rw,TpSk,Dq,TpBd),n_max = 2),tibble::tibble()),.progress = TRUE),
        one_minutes |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:9),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","TXS","Rw","TpSk","Dq","TpBd"),colClasses = c("V2" = "Date","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                                  dplyr::case_when(
                                                    # Site ID == ADC
                                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                                    # Site ID == 009
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID starts with 1
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID == 081 or 057
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                                    # Site ID mislabeled
                                                    .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                                  ),
                                                `Condition ID` = stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T))),
                                                `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                                Type = Type,
                                                TXS = TXS,
                                                Rw = Rw,
                                                TpSk = TpSk,
                                                Dq = Dq,
                                                TpBd = TpBd),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(3:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                                             `Date Time`,Type,TXS,Rw,TpSk,Dq,TpBd),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      # dplyr::distinct() |>
      dplyr::arrange(Path,`Subject ID`,`Condition ID`,`Date Time`) |>
      suppressWarnings()
  }
}

```


```{r}
  # Check packages
  packages <- c("tidyverse","haven","rlang")
  for (package_name in packages) {
    if (!require(package_name, character.only = TRUE)) {
      install <- readline(prompt = paste("Package", package_name, "is not installed. Do you want to install it? (Yes/No): "))
      # If say yes
      if (tolower(install) == "yes") {
        install.packages(package_name)
        library(package_name, character.only = TRUE)
        message(paste("Package", package_name, "has been installed and loaded."))
      }
       # If say no
       else {
        message(paste("Package", package_name, "was not installed."))
      }
    }
    #   else {
    #   message(paste("Package", package_name, "is already installed and loaded."))
    # }
  }
```

```{r}
oneminutes(events = path_filter(file_list, regexp = "*KETO.+events.csv$", ignore.case = T), one_minutes = path_filter(file_list, regexp = "*KETO.+oneMinutes.csv$", ignore.case = T),index = 55) |> View()
```

```{r}
file_list <- dir_ls(gsub("\\\\", "/", r"(M:\ADC-US-RES-24259\UploadData\Sensor_Data)"), 
                    regexp = "*devices.csv$|*readings.csv$", recurse = T) |> 
             path_filter(regexp = "Transfers|Transfer|Archive|Archives|LifeCount", invert = T, ignore.case = T)
```

```{r}
devices <- path_filter(file_list, regexp = "devices.csv")
readings <- path_filter(file_list, regexp = "readings.csv")
```
, activationTime= "T"
```{r}
devices[1] |> 
        purrr::set_names() |>
        map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SubjectID = "c", activationTime= "c"), show_col_types = F, col_select = c(SubjectID, ConditionID, sensorSN, activationTime)), tibble::tibble()), .progress = T) |> 
        map(\(df) df |> rename(timeLocal = activationTime)) |> 
    list_rbind() |> 
    mutate(ID = str_remove(timeLocal,"-[0-9][0-9]:00"),
           ID1 = ymd_hms(ID)) |> View()
```

```{r}
map2(
      # Devices.csv
        devices_path[index] |> 
        purrr::set_names() |>
        map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SiteID = "c", SubjectID = "c", activationTime= "c"), show_col_types = F, col_select = c(SiteID,SubjectID, ConditionID, sensorSN, activationTime)), tibble::tibble()), .progress = T) |> 
        map(\(df) df |> rename(timeLocal = activationTime)),
      # readings.csv  
      readings_path[index] |> 
          purrr::set_names() |>
          map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SiteID = "c", SubjectID = "c", lifecount = "c", timeLocal = "c", reading = "d"), show_col_types = F, 
             col_select = c(SiteID, SubjectID, ConditionID, lifecount, timeLocal, reading, analyte, uom, DataType)), tibble::tibble()), .progress = T), bind_rows) |> 
      # Fill sensor serial number 
      map(\(df) df |> fill(sensorSN), .progress = T) |> 
      list_rbind(names_to = "Path") |> 
      transmute(Path = Path,
                 Site = SiteID,
                `Subject ID` = SubjectID,
                `Condition ID` = ConditionID,
                `Sensor Serial Number` = sensorSN,
                 Lifecount = lifecount,
                `Date Time` = ymd_hms(str_remove(timeLocal,"-[0-9][0-9]:00")),
                 Analyte = analyte,
                 uom = uom,
                 Type = case_when(DataType == "raw" ~ "906",
                                  DataType == "historical" ~ "905",
                                  .default = "SENSOR_STARTED (58)"),
                 Reading = reading) |> 
      suppressWarnings()
```


```{r}
devices_readings1 <- function(devices_path, readings_path, index = NULL){

  if (length(devices_path) != length(readings_path)) {rlang::abort("Number of devices.csv is not equal to number of readings.csv!")}

  if (!is.numeric(index) && !is.null(index)) {rlang::abort("Index must be numeric!")}

  if(is.numeric(index)) {
    if (index > length(devices_path) || index > length(readings_path)) {rlang::abort("Index beyond the range!")}

    else {
      map2(
      # Devices.csv
        devices_path[index] |> 
        purrr::set_names() |>
        map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SiteID = "c", SubjectID = "c", activationTime= "c"), show_col_types = F, col_select = c(SiteID,SubjectID, ConditionID, sensorSN, activationTime)), tibble::tibble()), .progress = T) |> 
        map(\(df) df |> rename(timeLocal = activationTime)),
      # readings.csv  
      readings_path[index] |> 
          purrr::set_names() |>
          map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SiteID = "c", SubjectID = "c", lifecount = "c", timeLocal = "c", reading = "d"), show_col_types = F, 
             col_select = c(SiteID, SubjectID, ConditionID, lifecount, timeLocal, reading, analyte, uom, DataType)), tibble::tibble()), .progress = T), bind_rows) |> 
      # Fill sensor serial number 
      map(\(df) df |> fill(sensorSN), .progress = T) |> 
      list_rbind(names_to = "Path") |> 
      transmute(Path = Path,
                 Site = SiteID,
                `Subject ID` = SubjectID,
                `Condition ID` = ConditionID,
                `Sensor Serial Number` = sensorSN,
                 Lifecount = lifecount,
                `Date Time` = ymd_hms(str_remove(timeLocal,"-[0-9][0-9]:00")),
                 Analyte = analyte,
                 uom = uom,
                 Type = case_when(DataType == "raw" ~ "906",
                                  DataType == "historical" ~ "905",
                                  .default = "SENSOR_STARTED (58)"),
                 Reading = reading) |> 
      suppressWarnings()
    }
  }
  else if (is.null(index)) {
   map2(
      # Devices.csv
        devices_path |> 
        purrr::set_names() |>
        map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SiteID = "c", SubjectID = "c", activationTime= "c"), show_col_types = F, col_select = c(SiteID,SubjectID, ConditionID, sensorSN, activationTime)), tibble::tibble()), .progress = T) |> 
        map(\(df) df |> rename(timeLocal = activationTime)),
      # readings.csv  
      readings_path |> 
          purrr::set_names() |>
          map(possibly(\(path) vroom::vroom(path, delim = ",", col_types = c(SiteID = "c", SubjectID = "c", lifecount = "c", timeLocal = "c", reading = "d"), show_col_types = F, 
             col_select = c(SiteID, SubjectID, ConditionID, lifecount, timeLocal, reading, analyte, uom, DataType)), tibble::tibble()), .progress = T), bind_rows) |> 
      # Fill sensor serial number 
      map(\(df) df |> fill(sensorSN), .progress = T) |> 
      list_rbind(names_to = "Path") |> 
      transmute(Path = Path,
                 Site = SiteID,
                `Subject ID` = SubjectID,
                `Condition ID` = ConditionID,
                `Sensor Serial Number` = sensorSN,
                 Lifecount = lifecount,
                `Date Time` = ymd_hms(str_remove(timeLocal,"-[0-9][0-9]:00")),
                 Analyte = analyte,
                 uom = uom,
                 Type = case_when(DataType == "raw" ~ "906",
                                  DataType == "historical" ~ "905",
                                  .default = "SENSOR_STARTED (58)"),
                 Reading = reading) |> 
      suppressWarnings()
  }
}
```

```{r}
devices_readings1(devices_path = file_list |> path_filter(regexp = "devices.csv"),
                 readings_path = file_list |> path_filter(regexp = "readings.csv"),index = 120) |> View()
```

```{r}
devices_readings(devices_path = file_list |> path_filter(regexp = "devices.csv"),
                 readings_path = file_list |> path_filter(regexp = "readings.csv")) |> View()
```

```{r}
file_list <- dir_ls(gsub("\\\\", "/", r"(C:\UDP\OutputFiles\Output_2025-04-01-09-50\outputs)"), 
                    regexp = "*events.csv|*anaPlus.csv", recurse = T) |> 
             path_filter(regexp = "Transfers|Transfer|Archive|Archives|LifeCount", invert = T, ignore.case = T)
```

```{r}
mobi_anaPlus1 <- function(events, ana, index = NULL) {

  # Individual File
  if (is.numeric(index)) {
    purrr::map2(
      # First List
      # Import Events
      events[index] |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),

      purrr::map2(
        # Second List
        # Import anaPlus.csv or ana.csv
        ana[index] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Date = "c", Time = "c", Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,ANA,Rate,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        ana[index] |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","ANA","Rate","Tr"),colClasses = c("V2" = "character","V3" = "character","V4" = "character","V5" = "numeric","V6" = "numeric","V7" = "numeric")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                                  dplyr::case_when(
                                                    # Site ID == ADC
                                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                                    # Site ID == 009
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID starts with 1
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID == 081 or 057
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                                    # Site ID mislabeled
                                                    .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                                  ),
                                                `Condition ID` = stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T))),
                                                `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                                Type = Type,
                                                ANA = ANA,
                                                Rate = Rate,
                                                Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(2:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                                             `Date Time`,Type,ANA,Rate,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      suppressWarnings()

  } else {

    # All Upload Data
    purrr::map2(
      # First List
      # Import Events
      events |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
          Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE),

      purrr::map2(
        # Second List
        # Import anaPlus.csv or ana.csv
        ana |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Date = "c", Time = "c", Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,ANA,Rate,Tr),n_max = 2),tibble::tibble()),.progress = TRUE),
        ana |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","ANA","Rate","Tr"),colClasses = c("V2" = "character","V3" = "character","V4" = "character")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(`Subject ID` =
                                                  dplyr::case_when(
                                                    # Site ID == ADC
                                                    stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T))) == "ADC" ~ stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]{4}",ignore_case = T)),
                                                    # Site ID == 009
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{2}",ignore_case = T)) == "00" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 00).{1}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID starts with 1
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "1" ~
                                                      stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{3}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = ).{4}",ignore_case = T))),
                                                    # Site ID == 081 or 057
                                                    stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = ).{1}",ignore_case = T)) == "0" ~ stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = 0).{2}",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T))),
                                                    # Site ID mislabeled
                                                    .default = stringr::str_c(stringr::str_extract(df[1,1],stringr::regex("(?<=Site ID = )[:alnum:]+",ignore_case = T)),stringr::str_extract(df[1,1],stringr::regex("(?<=Subject ID = )[:digit:]+",ignore_case = T)))
                                                  ),
                                                `Condition ID` = stringr::str_to_upper(stringr::str_extract(df[1,1],stringr::regex("(?<=Condition ID = ).{3}",ignore_case = T))),
                                                `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
                                                Type = Type,
                                                ANA = ANA,
                                                Rate = Rate,
                                                Tr = Tr),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::slice(2:n())),dplyr::bind_rows,.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::arrange(`Date Time`),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(c(`Subject ID`,`Condition ID`),.direction = "up"),.progress = TRUE) |>
      purrr::map(\(df) df |> tidyr::fill(`Sensor Serial Number`,.direction = "down"),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::filter(!(!is.na(`Sensor Serial Number`) & is.na(`Date Time`))),.progress = TRUE) |>
      purrr::map(\(df) df |> dplyr::relocate(`Subject ID`,`Condition ID`,`Sensor Serial Number`,
                                             `Date Time`,Type,ANA,Rate,Tr),.progress = TRUE) |>
      purrr::list_rbind(names_to = "Path") |>
      # Remove Duplicated Uploads
      # dplyr::distinct() |>
      dplyr::arrange(Path,`Subject ID`,`Condition ID`,`Sensor Serial Number`) |>
      suppressWarnings()
  }
}
```

```{r}
#| label: Import events.csv and anaPlus.csv

file_list <- dir_ls(gsub("\\\\", "/", r"(C:\UDP\OutputFiles)"), 
                    regexp = "*events.csv|*anaPlus.csv|*oneMinutes.csv|*PC.txt|*rawData.csv", recurse = T) |> 
             # path_filter(regexp = "-251", ignore.case = T) |> 
             path_filter(regexp = "Transfers|Transfer|Archive|Archives|LifeCount", invert = T, ignore.case = T)
```

```{r}
mobi_anaPlus1(events = file_list |> path_filter(regexp = "*events.csv$", invert = F, ignore.case = T),
              ana = file_list |> path_filter(regexp = "*anaPlus.csv$", invert = F, ignore.case = T),index = 180)  |> View()
```

```{r}
(file_list |> 
   path_filter(regexp = "*events.csv$", invert = F, ignore.case = T))[19] |>
        purrr::set_names() |>
        # Consider empty events.csv
        purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Time = "c", Type = "c",`Col 9` = "c"),col_select = c(Date,Time,Type,`Col 9`)),tibble::tibble()),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::filter(Type == "SENSOR_STARTED (58)"),.progress = TRUE) |>
        purrr::map(\(df) df |> dplyr::transmute(
          `Date Time` = lubridate::ymd_hms(stringr::str_c(Date,Time,sep = " ")),
           Type = Type,
          `Sensor Serial Number` = `Col 9`),.progress = TRUE)
```

```{r}
purrr::map2(
        # Second List
        # Import anaPlus.csv or ana.csv
        (file_list |> 
          path_filter(regexp = "*anaPlus.csv$", invert = F, ignore.case = T))[19] |>
          purrr::map(purrr::possibly(\(path) vroom::vroom(path,delim = ",",col_names = T,show_col_types = F,col_types = c(Date = "c", Time = "c", Type = "c"),col_select = c(`Unique Record ID`,Date,Time,Type,ANA,Tr,Rate),n_max = 2),tibble::tibble()),.progress = TRUE),
        (file_list |> 
          path_filter(regexp = "*anaPlus.csv$", invert = F, ignore.case = T))[19] |>
          purrr::map(purrr::possibly(\(path) data.table::fread(path,select = c(1:7),skip = 3,col.names = c("Unique Record ID","Date","Time","Type","ANA","Rate","Tr"),colClasses = c("V2" = "character","V3" = "character","V4" = "character","V5" = "numeric","V6" = "numeric","V7" = "numeric")),tibble::tibble()),.progress = TRUE),
        dplyr::bind_rows,.progress = TRUE) |> 
      list_rbind() |> View()
```

```{r}

```

